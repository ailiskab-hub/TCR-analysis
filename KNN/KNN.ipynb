{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "175e91d6-9405-432b-9a07-376fdac2ef96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla V100S-PCIE-32GB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37905222-f201-4e96-8425-3138bd12b19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "# from my_model import CustomModel, PT5_classification_model, train_per_protein, create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a6a46ab-f3b4-4cd3-a701-b46e8bb11a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4ab820c-b7dd-4263-880a-071126094dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_spaces(seq):\n",
    "     return ' '.join(list(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b93b655d-8c2b-41e2-b14f-f26be02ebec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from epitopes.utilites import balance_majority, balance_minority, process_types, add_spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12c3fe05-de65-4af6-8814-db81006744d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-21 20:03:00,366] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from models_mdf import save_model, load_model_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d60439-9a8b-4de9-9231-ecc6cc26aa25",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f53e03b-06f6-4161-9807-5cb5d92725db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df with emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbed7de8-0463-4d24-9ef6-3ce77e505273",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = pd.read_csv('../data/balanced data for clf/train_alpha.csv')\n",
    "beta = pd.read_csv('../data/balanced data for clf/train_beta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "983a6dad-dd00-4d70-935d-a3b2b61b3675",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LABELS_av = alpha['v'].nunique()\n",
    "N_LABELS_aj = alpha['j'].nunique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475d7f60-befb-45b7-a569-bd4fc9e2ef25",
   "metadata": {},
   "source": [
    "## J GENES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68d2eacf-f47d-48cf-8da2-b337608eb815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at wukevin/tcr-bert-mlm-only were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at wukevin/tcr-bert-mlm-only and are newly initialized: ['classifier.bias', 'bert.pooler.dense.bias', 'classifier.weight', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "aJ_model = load_model_('../models/VJ_clf_transf/TCRbert_alfa_j.pth', mod_type='TCR-bert', num_labels=N_LABELS_aj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b05e51c-1921-42c2-b371-acee3ba7c1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "aj_df = alpha[['cdr3aa', 'j']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fcb01f9-8bed-4a5a-bf3c-dbe1b7f2cd82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cdr3aa</th>\n",
       "      <th>j</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAAIGGSTLGRLYF</td>\n",
       "      <td>TRAJ18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAASFSGYSTLTF</td>\n",
       "      <td>TRAJ11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CALGDGGNYQLIW</td>\n",
       "      <td>TRAJ33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CALFDFGNEKLTF</td>\n",
       "      <td>TRAJ48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAGSKNAGKSTF</td>\n",
       "      <td>TRAJ27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26029</th>\n",
       "      <td>CAVLPLYGGSQGNLIF</td>\n",
       "      <td>TRAJ42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26030</th>\n",
       "      <td>CAEIPNYGGSQGNLIF</td>\n",
       "      <td>TRAJ42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26031</th>\n",
       "      <td>CAMRDYNVLYF</td>\n",
       "      <td>TRAJ21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26032</th>\n",
       "      <td>CLVAVPADTGRRALTF</td>\n",
       "      <td>TRAJ5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26033</th>\n",
       "      <td>CAVPFKGAQKLVF</td>\n",
       "      <td>TRAJ54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26034 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 cdr3aa       j\n",
       "0        CAAIGGSTLGRLYF  TRAJ18\n",
       "1         CAASFSGYSTLTF  TRAJ11\n",
       "2         CALGDGGNYQLIW  TRAJ33\n",
       "3         CALFDFGNEKLTF  TRAJ48\n",
       "4          CAGSKNAGKSTF  TRAJ27\n",
       "...                 ...     ...\n",
       "26029  CAVLPLYGGSQGNLIF  TRAJ42\n",
       "26030  CAEIPNYGGSQGNLIF  TRAJ42\n",
       "26031       CAMRDYNVLYF  TRAJ21\n",
       "26032  CLVAVPADTGRRALTF   TRAJ5\n",
       "26033     CAVPFKGAQKLVF  TRAJ54\n",
       "\n",
       "[26034 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aj_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cfb11f6-ea3d-4fb3-a5db-09d9e8400ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_1877052/3544759591.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  aj_df['cdr3aa'] = aj_df['cdr3aa'].apply(add_spaces)\n",
      "/scratch/ipykernel_1877052/3544759591.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  aj_df['j'] = l_enc_j.transform(aj_df['j'])\n"
     ]
    }
   ],
   "source": [
    "aj_df['cdr3aa'] = aj_df['cdr3aa'].apply(add_spaces)\n",
    "\n",
    "l_enc_j = LabelEncoder()\n",
    "l_enc_j.fit(aj_df['j'])\n",
    "aj_df['j'] = l_enc_j.transform(aj_df['j'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cab51948-e853-4ff9-959a-4454373039ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict(zip(l_enc_j.classes_, range(len(l_enc_j.classes_))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30612f9e-a5b7-4d78-b8b8-3a795df7f3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from knn_setup import create_df_embs, train_clf, get_nearest_neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09de9767-9e1e-4fbc-981d-9cb30d2a94fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29c4d213-2db4-44bd-aea2-94ffba9fd8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10414/10414 [09:35<00:00, 18.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.647340</td>\n",
       "      <td>-0.560809</td>\n",
       "      <td>-0.001305</td>\n",
       "      <td>-0.163974</td>\n",
       "      <td>0.079416</td>\n",
       "      <td>0.108241</td>\n",
       "      <td>-0.344863</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.228859</td>\n",
       "      <td>-0.667988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697033</td>\n",
       "      <td>-0.052007</td>\n",
       "      <td>0.314567</td>\n",
       "      <td>-0.174897</td>\n",
       "      <td>0.279822</td>\n",
       "      <td>-0.411745</td>\n",
       "      <td>-0.510936</td>\n",
       "      <td>-0.378025</td>\n",
       "      <td>0.482202</td>\n",
       "      <td>0.124261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.244388</td>\n",
       "      <td>-1.582390</td>\n",
       "      <td>-0.431907</td>\n",
       "      <td>-0.549375</td>\n",
       "      <td>-0.077844</td>\n",
       "      <td>0.631082</td>\n",
       "      <td>-0.203106</td>\n",
       "      <td>-0.494974</td>\n",
       "      <td>-0.564094</td>\n",
       "      <td>-0.028760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001689</td>\n",
       "      <td>-0.424484</td>\n",
       "      <td>-0.072142</td>\n",
       "      <td>-0.263264</td>\n",
       "      <td>-0.456467</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>-0.364723</td>\n",
       "      <td>-0.508019</td>\n",
       "      <td>1.004848</td>\n",
       "      <td>-0.505774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.784028</td>\n",
       "      <td>-0.616249</td>\n",
       "      <td>-0.240298</td>\n",
       "      <td>-0.145131</td>\n",
       "      <td>0.100028</td>\n",
       "      <td>-0.121540</td>\n",
       "      <td>-0.361889</td>\n",
       "      <td>-0.119354</td>\n",
       "      <td>-0.008641</td>\n",
       "      <td>-0.110913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085095</td>\n",
       "      <td>-0.303054</td>\n",
       "      <td>0.219602</td>\n",
       "      <td>-0.442124</td>\n",
       "      <td>-0.178131</td>\n",
       "      <td>-0.117636</td>\n",
       "      <td>-0.350745</td>\n",
       "      <td>-0.340547</td>\n",
       "      <td>0.307560</td>\n",
       "      <td>-0.490311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.348778</td>\n",
       "      <td>-0.405088</td>\n",
       "      <td>-0.076944</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.470691</td>\n",
       "      <td>0.136137</td>\n",
       "      <td>-0.211244</td>\n",
       "      <td>0.324338</td>\n",
       "      <td>0.096805</td>\n",
       "      <td>0.327968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336686</td>\n",
       "      <td>-0.315851</td>\n",
       "      <td>0.124372</td>\n",
       "      <td>-0.311242</td>\n",
       "      <td>-0.696494</td>\n",
       "      <td>-0.429463</td>\n",
       "      <td>-0.213975</td>\n",
       "      <td>-0.279047</td>\n",
       "      <td>0.266973</td>\n",
       "      <td>0.230128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.004334</td>\n",
       "      <td>-0.499696</td>\n",
       "      <td>0.008729</td>\n",
       "      <td>-0.030454</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.122900</td>\n",
       "      <td>-0.192133</td>\n",
       "      <td>-0.110254</td>\n",
       "      <td>-0.351567</td>\n",
       "      <td>-0.168506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275831</td>\n",
       "      <td>0.035123</td>\n",
       "      <td>0.090992</td>\n",
       "      <td>0.045417</td>\n",
       "      <td>-0.145398</td>\n",
       "      <td>-0.203661</td>\n",
       "      <td>-0.184373</td>\n",
       "      <td>-0.248784</td>\n",
       "      <td>0.783612</td>\n",
       "      <td>0.009645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.647340 -0.560809 -0.001305 -0.163974  0.079416  0.108241 -0.344863   \n",
       "1  0.244388 -1.582390 -0.431907 -0.549375 -0.077844  0.631082 -0.203106   \n",
       "2 -0.784028 -0.616249 -0.240298 -0.145131  0.100028 -0.121540 -0.361889   \n",
       "3 -0.348778 -0.405088 -0.076944  0.001057  0.470691  0.136137 -0.211244   \n",
       "4 -0.004334 -0.499696  0.008729 -0.030454  0.001965  0.122900 -0.192133   \n",
       "\n",
       "        7         8         9    ...       758       759       760       761  \\\n",
       "0  0.001524  0.228859 -0.667988  ...  0.697033 -0.052007  0.314567 -0.174897   \n",
       "1 -0.494974 -0.564094 -0.028760  ...  0.001689 -0.424484 -0.072142 -0.263264   \n",
       "2 -0.119354 -0.008641 -0.110913  ...  0.085095 -0.303054  0.219602 -0.442124   \n",
       "3  0.324338  0.096805  0.327968  ...  0.336686 -0.315851  0.124372 -0.311242   \n",
       "4 -0.110254 -0.351567 -0.168506  ...  0.275831  0.035123  0.090992  0.045417   \n",
       "\n",
       "        762       763       764       765       766       767  \n",
       "0  0.279822 -0.411745 -0.510936 -0.378025  0.482202  0.124261  \n",
       "1 -0.456467  0.001980 -0.364723 -0.508019  1.004848 -0.505774  \n",
       "2 -0.178131 -0.117636 -0.350745 -0.340547  0.307560 -0.490311  \n",
       "3 -0.696494 -0.429463 -0.213975 -0.279047  0.266973  0.230128  \n",
       "4 -0.145398 -0.203661 -0.184373 -0.248784  0.783612  0.009645  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aj_df = aj_df.sample(frac=0.4, random_state=42)\n",
    "\n",
    "df_j_emb = create_df_embs(aJ_model, aj_df)\n",
    "# df_j_emb = pd.read_csv('df_j_emb.csv', index_col=0)\n",
    "df_j_emb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ec7ca7c-8e6a-4178-a7bc-c08763aa0528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>768</th>\n",
       "      <th>769</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C L V G A P G Y S S A S K I I F</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.647340</td>\n",
       "      <td>-0.560809</td>\n",
       "      <td>-0.001305</td>\n",
       "      <td>-0.163974</td>\n",
       "      <td>0.079416</td>\n",
       "      <td>0.108241</td>\n",
       "      <td>-0.344863</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697033</td>\n",
       "      <td>-0.052007</td>\n",
       "      <td>0.314567</td>\n",
       "      <td>-0.174897</td>\n",
       "      <td>0.279822</td>\n",
       "      <td>-0.411745</td>\n",
       "      <td>-0.510936</td>\n",
       "      <td>-0.378025</td>\n",
       "      <td>0.482202</td>\n",
       "      <td>0.124261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C A L L G R L Y F</td>\n",
       "      <td>7</td>\n",
       "      <td>0.244388</td>\n",
       "      <td>-1.582390</td>\n",
       "      <td>-0.431907</td>\n",
       "      <td>-0.549375</td>\n",
       "      <td>-0.077844</td>\n",
       "      <td>0.631082</td>\n",
       "      <td>-0.203106</td>\n",
       "      <td>-0.494974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001689</td>\n",
       "      <td>-0.424484</td>\n",
       "      <td>-0.072142</td>\n",
       "      <td>-0.263264</td>\n",
       "      <td>-0.456467</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>-0.364723</td>\n",
       "      <td>-0.508019</td>\n",
       "      <td>1.004848</td>\n",
       "      <td>-0.505774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C G T S N S G G S N Y K L T F</td>\n",
       "      <td>39</td>\n",
       "      <td>-0.784028</td>\n",
       "      <td>-0.616249</td>\n",
       "      <td>-0.240298</td>\n",
       "      <td>-0.145131</td>\n",
       "      <td>0.100028</td>\n",
       "      <td>-0.121540</td>\n",
       "      <td>-0.361889</td>\n",
       "      <td>-0.119354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085095</td>\n",
       "      <td>-0.303054</td>\n",
       "      <td>0.219602</td>\n",
       "      <td>-0.442124</td>\n",
       "      <td>-0.178131</td>\n",
       "      <td>-0.117636</td>\n",
       "      <td>-0.350745</td>\n",
       "      <td>-0.340547</td>\n",
       "      <td>0.307560</td>\n",
       "      <td>-0.490311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C A E S K E G K L I F</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.348778</td>\n",
       "      <td>-0.405088</td>\n",
       "      <td>-0.076944</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.470691</td>\n",
       "      <td>0.136137</td>\n",
       "      <td>-0.211244</td>\n",
       "      <td>0.324338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336686</td>\n",
       "      <td>-0.315851</td>\n",
       "      <td>0.124372</td>\n",
       "      <td>-0.311242</td>\n",
       "      <td>-0.696494</td>\n",
       "      <td>-0.429463</td>\n",
       "      <td>-0.213975</td>\n",
       "      <td>-0.279047</td>\n",
       "      <td>0.266973</td>\n",
       "      <td>0.230128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C A G Q L Y G G S Q G N L I F</td>\n",
       "      <td>29</td>\n",
       "      <td>-0.004334</td>\n",
       "      <td>-0.499696</td>\n",
       "      <td>0.008729</td>\n",
       "      <td>-0.030454</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.122900</td>\n",
       "      <td>-0.192133</td>\n",
       "      <td>-0.110254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275831</td>\n",
       "      <td>0.035123</td>\n",
       "      <td>0.090992</td>\n",
       "      <td>0.045417</td>\n",
       "      <td>-0.145398</td>\n",
       "      <td>-0.203661</td>\n",
       "      <td>-0.184373</td>\n",
       "      <td>-0.248784</td>\n",
       "      <td>0.783612</td>\n",
       "      <td>0.009645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 770 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0    1         2         3         4    \\\n",
       "0  C L V G A P G Y S S A S K I I F   17 -0.647340 -0.560809 -0.001305   \n",
       "1                C A L L G R L Y F    7  0.244388 -1.582390 -0.431907   \n",
       "2    C G T S N S G G S N Y K L T F   39 -0.784028 -0.616249 -0.240298   \n",
       "3            C A E S K E G K L I F   24 -0.348778 -0.405088 -0.076944   \n",
       "4    C A G Q L Y G G S Q G N L I F   29 -0.004334 -0.499696  0.008729   \n",
       "\n",
       "        5         6         7         8         9    ...       760       761  \\\n",
       "0 -0.163974  0.079416  0.108241 -0.344863  0.001524  ...  0.697033 -0.052007   \n",
       "1 -0.549375 -0.077844  0.631082 -0.203106 -0.494974  ...  0.001689 -0.424484   \n",
       "2 -0.145131  0.100028 -0.121540 -0.361889 -0.119354  ...  0.085095 -0.303054   \n",
       "3  0.001057  0.470691  0.136137 -0.211244  0.324338  ...  0.336686 -0.315851   \n",
       "4 -0.030454  0.001965  0.122900 -0.192133 -0.110254  ...  0.275831  0.035123   \n",
       "\n",
       "        762       763       764       765       766       767       768  \\\n",
       "0  0.314567 -0.174897  0.279822 -0.411745 -0.510936 -0.378025  0.482202   \n",
       "1 -0.072142 -0.263264 -0.456467  0.001980 -0.364723 -0.508019  1.004848   \n",
       "2  0.219602 -0.442124 -0.178131 -0.117636 -0.350745 -0.340547  0.307560   \n",
       "3  0.124372 -0.311242 -0.696494 -0.429463 -0.213975 -0.279047  0.266973   \n",
       "4  0.090992  0.045417 -0.145398 -0.203661 -0.184373 -0.248784  0.783612   \n",
       "\n",
       "        769  \n",
       "0  0.124261  \n",
       "1 -0.505774  \n",
       "2 -0.490311  \n",
       "3  0.230128  \n",
       "4  0.009645  \n",
       "\n",
       "[5 rows x 770 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aj_df = aj_df.reset_index(drop=True)\n",
    "df_j_emb = pd.concat([aj_df, df_j_emb], axis=1, ignore_index=True)\n",
    "df_j_emb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26b717c1-c092-4728-af8a-de620c6b48f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>768</th>\n",
       "      <th>769</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.647340</td>\n",
       "      <td>-0.560809</td>\n",
       "      <td>-0.001305</td>\n",
       "      <td>-0.163974</td>\n",
       "      <td>0.079416</td>\n",
       "      <td>0.108241</td>\n",
       "      <td>-0.344863</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.228859</td>\n",
       "      <td>-0.667988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697033</td>\n",
       "      <td>-0.052007</td>\n",
       "      <td>0.314567</td>\n",
       "      <td>-0.174897</td>\n",
       "      <td>0.279822</td>\n",
       "      <td>-0.411745</td>\n",
       "      <td>-0.510936</td>\n",
       "      <td>-0.378025</td>\n",
       "      <td>0.482202</td>\n",
       "      <td>0.124261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.244388</td>\n",
       "      <td>-1.582390</td>\n",
       "      <td>-0.431907</td>\n",
       "      <td>-0.549375</td>\n",
       "      <td>-0.077844</td>\n",
       "      <td>0.631082</td>\n",
       "      <td>-0.203106</td>\n",
       "      <td>-0.494974</td>\n",
       "      <td>-0.564094</td>\n",
       "      <td>-0.028760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001689</td>\n",
       "      <td>-0.424484</td>\n",
       "      <td>-0.072142</td>\n",
       "      <td>-0.263264</td>\n",
       "      <td>-0.456467</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>-0.364723</td>\n",
       "      <td>-0.508019</td>\n",
       "      <td>1.004848</td>\n",
       "      <td>-0.505774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.784028</td>\n",
       "      <td>-0.616249</td>\n",
       "      <td>-0.240298</td>\n",
       "      <td>-0.145131</td>\n",
       "      <td>0.100028</td>\n",
       "      <td>-0.121540</td>\n",
       "      <td>-0.361889</td>\n",
       "      <td>-0.119354</td>\n",
       "      <td>-0.008641</td>\n",
       "      <td>-0.110913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085095</td>\n",
       "      <td>-0.303054</td>\n",
       "      <td>0.219602</td>\n",
       "      <td>-0.442124</td>\n",
       "      <td>-0.178131</td>\n",
       "      <td>-0.117636</td>\n",
       "      <td>-0.350745</td>\n",
       "      <td>-0.340547</td>\n",
       "      <td>0.307560</td>\n",
       "      <td>-0.490311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.348778</td>\n",
       "      <td>-0.405088</td>\n",
       "      <td>-0.076944</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.470691</td>\n",
       "      <td>0.136137</td>\n",
       "      <td>-0.211244</td>\n",
       "      <td>0.324338</td>\n",
       "      <td>0.096805</td>\n",
       "      <td>0.327968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336686</td>\n",
       "      <td>-0.315851</td>\n",
       "      <td>0.124372</td>\n",
       "      <td>-0.311242</td>\n",
       "      <td>-0.696494</td>\n",
       "      <td>-0.429463</td>\n",
       "      <td>-0.213975</td>\n",
       "      <td>-0.279047</td>\n",
       "      <td>0.266973</td>\n",
       "      <td>0.230128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.004334</td>\n",
       "      <td>-0.499696</td>\n",
       "      <td>0.008729</td>\n",
       "      <td>-0.030454</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.122900</td>\n",
       "      <td>-0.192133</td>\n",
       "      <td>-0.110254</td>\n",
       "      <td>-0.351567</td>\n",
       "      <td>-0.168506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275831</td>\n",
       "      <td>0.035123</td>\n",
       "      <td>0.090992</td>\n",
       "      <td>0.045417</td>\n",
       "      <td>-0.145398</td>\n",
       "      <td>-0.203661</td>\n",
       "      <td>-0.184373</td>\n",
       "      <td>-0.248784</td>\n",
       "      <td>0.783612</td>\n",
       "      <td>0.009645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10409</th>\n",
       "      <td>0.107218</td>\n",
       "      <td>-0.597809</td>\n",
       "      <td>-0.866804</td>\n",
       "      <td>-0.205675</td>\n",
       "      <td>-0.075828</td>\n",
       "      <td>-0.023055</td>\n",
       "      <td>-0.754772</td>\n",
       "      <td>-0.062797</td>\n",
       "      <td>-0.259994</td>\n",
       "      <td>-0.861944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215896</td>\n",
       "      <td>0.024436</td>\n",
       "      <td>-0.073342</td>\n",
       "      <td>0.036956</td>\n",
       "      <td>0.166490</td>\n",
       "      <td>-0.018310</td>\n",
       "      <td>-0.111455</td>\n",
       "      <td>-0.747917</td>\n",
       "      <td>0.380730</td>\n",
       "      <td>-0.013440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10410</th>\n",
       "      <td>-0.635970</td>\n",
       "      <td>-0.024376</td>\n",
       "      <td>-0.256344</td>\n",
       "      <td>0.081329</td>\n",
       "      <td>0.473106</td>\n",
       "      <td>0.133732</td>\n",
       "      <td>-0.104639</td>\n",
       "      <td>-0.047496</td>\n",
       "      <td>0.370318</td>\n",
       "      <td>-0.154011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.308429</td>\n",
       "      <td>0.017407</td>\n",
       "      <td>0.530394</td>\n",
       "      <td>0.210666</td>\n",
       "      <td>0.109712</td>\n",
       "      <td>0.155375</td>\n",
       "      <td>-0.598735</td>\n",
       "      <td>-0.228948</td>\n",
       "      <td>0.175603</td>\n",
       "      <td>0.011674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10411</th>\n",
       "      <td>-0.795809</td>\n",
       "      <td>-0.259600</td>\n",
       "      <td>-0.079311</td>\n",
       "      <td>-0.283488</td>\n",
       "      <td>0.139523</td>\n",
       "      <td>0.138584</td>\n",
       "      <td>-0.328737</td>\n",
       "      <td>-0.457066</td>\n",
       "      <td>0.073675</td>\n",
       "      <td>-0.150348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429378</td>\n",
       "      <td>-0.370843</td>\n",
       "      <td>0.258513</td>\n",
       "      <td>-0.183225</td>\n",
       "      <td>-0.366565</td>\n",
       "      <td>-0.036393</td>\n",
       "      <td>-0.232845</td>\n",
       "      <td>-0.197336</td>\n",
       "      <td>-0.041201</td>\n",
       "      <td>-0.134115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10412</th>\n",
       "      <td>-0.112686</td>\n",
       "      <td>-0.303925</td>\n",
       "      <td>-0.460364</td>\n",
       "      <td>-0.194952</td>\n",
       "      <td>0.481558</td>\n",
       "      <td>0.305201</td>\n",
       "      <td>-0.191374</td>\n",
       "      <td>-0.143161</td>\n",
       "      <td>0.253668</td>\n",
       "      <td>-0.369667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053475</td>\n",
       "      <td>0.110446</td>\n",
       "      <td>0.393816</td>\n",
       "      <td>0.040140</td>\n",
       "      <td>0.210204</td>\n",
       "      <td>-0.060648</td>\n",
       "      <td>-0.429888</td>\n",
       "      <td>-0.393008</td>\n",
       "      <td>0.563790</td>\n",
       "      <td>-0.032604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10413</th>\n",
       "      <td>0.263613</td>\n",
       "      <td>-0.276667</td>\n",
       "      <td>-0.464737</td>\n",
       "      <td>0.295402</td>\n",
       "      <td>-0.284967</td>\n",
       "      <td>0.183782</td>\n",
       "      <td>-0.241568</td>\n",
       "      <td>-0.655398</td>\n",
       "      <td>0.305815</td>\n",
       "      <td>-0.233970</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010509</td>\n",
       "      <td>-0.198000</td>\n",
       "      <td>0.260047</td>\n",
       "      <td>-0.028969</td>\n",
       "      <td>-0.365743</td>\n",
       "      <td>0.154076</td>\n",
       "      <td>0.235460</td>\n",
       "      <td>-0.811921</td>\n",
       "      <td>0.383627</td>\n",
       "      <td>0.293308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10414 rows Ã— 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            2         3         4         5         6         7         8    \\\n",
       "0     -0.647340 -0.560809 -0.001305 -0.163974  0.079416  0.108241 -0.344863   \n",
       "1      0.244388 -1.582390 -0.431907 -0.549375 -0.077844  0.631082 -0.203106   \n",
       "2     -0.784028 -0.616249 -0.240298 -0.145131  0.100028 -0.121540 -0.361889   \n",
       "3     -0.348778 -0.405088 -0.076944  0.001057  0.470691  0.136137 -0.211244   \n",
       "4     -0.004334 -0.499696  0.008729 -0.030454  0.001965  0.122900 -0.192133   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "10409  0.107218 -0.597809 -0.866804 -0.205675 -0.075828 -0.023055 -0.754772   \n",
       "10410 -0.635970 -0.024376 -0.256344  0.081329  0.473106  0.133732 -0.104639   \n",
       "10411 -0.795809 -0.259600 -0.079311 -0.283488  0.139523  0.138584 -0.328737   \n",
       "10412 -0.112686 -0.303925 -0.460364 -0.194952  0.481558  0.305201 -0.191374   \n",
       "10413  0.263613 -0.276667 -0.464737  0.295402 -0.284967  0.183782 -0.241568   \n",
       "\n",
       "            9         10        11   ...       760       761       762  \\\n",
       "0      0.001524  0.228859 -0.667988  ...  0.697033 -0.052007  0.314567   \n",
       "1     -0.494974 -0.564094 -0.028760  ...  0.001689 -0.424484 -0.072142   \n",
       "2     -0.119354 -0.008641 -0.110913  ...  0.085095 -0.303054  0.219602   \n",
       "3      0.324338  0.096805  0.327968  ...  0.336686 -0.315851  0.124372   \n",
       "4     -0.110254 -0.351567 -0.168506  ...  0.275831  0.035123  0.090992   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "10409 -0.062797 -0.259994 -0.861944  ...  0.215896  0.024436 -0.073342   \n",
       "10410 -0.047496  0.370318 -0.154011  ...  0.308429  0.017407  0.530394   \n",
       "10411 -0.457066  0.073675 -0.150348  ...  0.429378 -0.370843  0.258513   \n",
       "10412 -0.143161  0.253668 -0.369667  ...  0.053475  0.110446  0.393816   \n",
       "10413 -0.655398  0.305815 -0.233970  ... -0.010509 -0.198000  0.260047   \n",
       "\n",
       "            763       764       765       766       767       768       769  \n",
       "0     -0.174897  0.279822 -0.411745 -0.510936 -0.378025  0.482202  0.124261  \n",
       "1     -0.263264 -0.456467  0.001980 -0.364723 -0.508019  1.004848 -0.505774  \n",
       "2     -0.442124 -0.178131 -0.117636 -0.350745 -0.340547  0.307560 -0.490311  \n",
       "3     -0.311242 -0.696494 -0.429463 -0.213975 -0.279047  0.266973  0.230128  \n",
       "4      0.045417 -0.145398 -0.203661 -0.184373 -0.248784  0.783612  0.009645  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "10409  0.036956  0.166490 -0.018310 -0.111455 -0.747917  0.380730 -0.013440  \n",
       "10410  0.210666  0.109712  0.155375 -0.598735 -0.228948  0.175603  0.011674  \n",
       "10411 -0.183225 -0.366565 -0.036393 -0.232845 -0.197336 -0.041201 -0.134115  \n",
       "10412  0.040140  0.210204 -0.060648 -0.429888 -0.393008  0.563790 -0.032604  \n",
       "10413 -0.028969 -0.365743  0.154076  0.235460 -0.811921  0.383627  0.293308  \n",
       "\n",
       "[10414 rows x 768 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_j_emb.drop([0, 1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5ccd5c5-6f72-457e-8b2a-dcb37285b83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# df_j_emb.drop(columns = ['cdr3aa'], inplace=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_j_emb.drop([0, 1], axis=1), df_j_emb[1], test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e78b7ed-a4dd-42a7-a176-8c3ce2dfeadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pickle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c64c630-caf8-4e07-8bc2-108320a4706c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Best CV score: 0.997, best CV k: KNeighborsClassifier(n_neighbors=10, weights='distance')\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akabalina/.conda/envs/ft/lib/python3.9/site-packages/threadpoolctl.py:1226: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting test score: 0.993\n"
     ]
    }
   ],
   "source": [
    "knn_best = train_clf(X_train, X_test, y_train, y_test, gene='j', save=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "926195d2-9f21-4b58-ab82-f3f37f5fc19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Point: C A L F D F G N E K L T F\n",
      "Nearest Neighbors: [6957, 2581, 1778, 1928, 4283, 3548, 558, 1502, 2773, 8136]\n",
      "Nearest Labels: [34 34 34 34 34 34 34 34 34 34]\n",
      "Distances to Nearest Neighbors: [[1.1045881  2.21314547 2.78202561 2.79092794 2.80230889 2.80850398\n",
      "  2.80850398 2.82770409 2.94296435 2.94377723]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akabalina/.conda/envs/ft/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "nn_j = get_nearest_neighbours('./knn_j_model.pkl', aJ_model, 'C A L F D F G N E K L T F', X_train, y_train, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f29d19d6-8923-494f-8fb6-e1070acc1977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TRAJ48', 'TRAJ48', 'TRAJ48', 'TRAJ48', 'TRAJ48', 'TRAJ48',\n",
       "       'TRAJ48', 'TRAJ48', 'TRAJ48', 'TRAJ48'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_enc_j.inverse_transform(y_train.loc[nn_j].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10e52a9-9efb-4b53-b94b-57f5a00a29da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "544b0d94-ba1e-4f1c-a53f-eb6b45b48fee",
   "metadata": {},
   "source": [
    "## V GENES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6b0629e-7df2-45a3-b639-f0d06c8d686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LABELS_av = alpha['v'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc98eb2f-568c-4740-862f-f17888eae294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at wukevin/tcr-bert-mlm-only were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at wukevin/tcr-bert-mlm-only and are newly initialized: ['classifier.bias', 'bert.pooler.dense.bias', 'classifier.weight', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "av_model = load_model_('../models/VJ_clf_transf/TCRbert_alfa_v.pth', mod_type='TCR-bert', num_labels=N_LABELS_av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1df7e562-b628-4e1a-9aff-1e7b7c7f45a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "av_df = alpha[['cdr3aa', 'v']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a103babf-05b5-4696-b895-8d5669e8efce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cdr3aa</th>\n",
       "      <th>v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAAIGGSTLGRLYF</td>\n",
       "      <td>TRAV29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAASFSGYSTLTF</td>\n",
       "      <td>TRAV13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CALGDGGNYQLIW</td>\n",
       "      <td>TRAV6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CALFDFGNEKLTF</td>\n",
       "      <td>TRAV16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAGSKNAGKSTF</td>\n",
       "      <td>TRAV25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26029</th>\n",
       "      <td>CAVLPLYGGSQGNLIF</td>\n",
       "      <td>TRAV39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26030</th>\n",
       "      <td>CAEIPNYGGSQGNLIF</td>\n",
       "      <td>TRAV5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26031</th>\n",
       "      <td>CAMRDYNVLYF</td>\n",
       "      <td>TRAV16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26032</th>\n",
       "      <td>CLVAVPADTGRRALTF</td>\n",
       "      <td>TRAV4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26033</th>\n",
       "      <td>CAVPFKGAQKLVF</td>\n",
       "      <td>TRAV41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26034 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 cdr3aa       v\n",
       "0        CAAIGGSTLGRLYF  TRAV29\n",
       "1         CAASFSGYSTLTF  TRAV13\n",
       "2         CALGDGGNYQLIW   TRAV6\n",
       "3         CALFDFGNEKLTF  TRAV16\n",
       "4          CAGSKNAGKSTF  TRAV25\n",
       "...                 ...     ...\n",
       "26029  CAVLPLYGGSQGNLIF  TRAV39\n",
       "26030  CAEIPNYGGSQGNLIF   TRAV5\n",
       "26031       CAMRDYNVLYF  TRAV16\n",
       "26032  CLVAVPADTGRRALTF   TRAV4\n",
       "26033     CAVPFKGAQKLVF  TRAV41\n",
       "\n",
       "[26034 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df3f564a-1d0e-40f1-a11b-d4791bcb8bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_1877052/1536563190.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  av_df['cdr3aa'] = av_df['cdr3aa'].apply(add_spaces)\n",
      "/scratch/ipykernel_1877052/1536563190.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  av_df['v'] = l_enc_v.transform(av_df['v'])\n"
     ]
    }
   ],
   "source": [
    "av_df['cdr3aa'] = av_df['cdr3aa'].apply(add_spaces)\n",
    "\n",
    "l_enc_v = LabelEncoder()\n",
    "l_enc_v.fit(av_df['v'])\n",
    "av_df['v'] = l_enc_v.transform(av_df['v'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5d586da-ff47-49c7-b658-2d841f035b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict(zip(l_enc_v.classes_, range(len(l_enc_v.classes_))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cbaf7ad0-c02d-47ed-aa33-d3336f022029",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10414/10414 [09:47<00:00, 17.73it/s]\n"
     ]
    }
   ],
   "source": [
    "av_df = av_df.sample(frac=0.4, random_state=42)\n",
    "\n",
    "df_v_emb = create_df_embs(av_model, av_df)\n",
    "# df_v_emb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "234819f6-c8a6-48fb-b591-dfee4d06c795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>768</th>\n",
       "      <th>769</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C L V G A P G Y S S A S K I I F</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.634476</td>\n",
       "      <td>-0.715426</td>\n",
       "      <td>-0.112857</td>\n",
       "      <td>-0.026188</td>\n",
       "      <td>-0.163004</td>\n",
       "      <td>0.403640</td>\n",
       "      <td>-0.354486</td>\n",
       "      <td>-0.028810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525054</td>\n",
       "      <td>-0.023938</td>\n",
       "      <td>0.282135</td>\n",
       "      <td>-0.311814</td>\n",
       "      <td>0.185906</td>\n",
       "      <td>-0.352735</td>\n",
       "      <td>-0.448487</td>\n",
       "      <td>0.025638</td>\n",
       "      <td>0.497169</td>\n",
       "      <td>0.047479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C A L L G R L Y F</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.197206</td>\n",
       "      <td>-0.869457</td>\n",
       "      <td>-0.575098</td>\n",
       "      <td>-0.589052</td>\n",
       "      <td>0.364810</td>\n",
       "      <td>0.425240</td>\n",
       "      <td>-0.285844</td>\n",
       "      <td>-0.439713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448100</td>\n",
       "      <td>-0.214829</td>\n",
       "      <td>-0.188320</td>\n",
       "      <td>-0.257455</td>\n",
       "      <td>-0.381339</td>\n",
       "      <td>0.370652</td>\n",
       "      <td>-0.898810</td>\n",
       "      <td>-0.381585</td>\n",
       "      <td>0.596959</td>\n",
       "      <td>0.254778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C G T S N S G G S N Y K L T F</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.356926</td>\n",
       "      <td>-0.407020</td>\n",
       "      <td>0.011429</td>\n",
       "      <td>0.016217</td>\n",
       "      <td>0.150756</td>\n",
       "      <td>0.267557</td>\n",
       "      <td>-0.530167</td>\n",
       "      <td>-0.358644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266957</td>\n",
       "      <td>-0.431619</td>\n",
       "      <td>0.063431</td>\n",
       "      <td>-0.255619</td>\n",
       "      <td>-0.081371</td>\n",
       "      <td>-0.068055</td>\n",
       "      <td>-0.308897</td>\n",
       "      <td>-0.062996</td>\n",
       "      <td>0.249711</td>\n",
       "      <td>0.156963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C A E S K E G K L I F</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.119118</td>\n",
       "      <td>-0.653685</td>\n",
       "      <td>-0.765995</td>\n",
       "      <td>0.080028</td>\n",
       "      <td>0.234760</td>\n",
       "      <td>0.119031</td>\n",
       "      <td>-0.130814</td>\n",
       "      <td>-0.172284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.301340</td>\n",
       "      <td>-0.249289</td>\n",
       "      <td>0.098097</td>\n",
       "      <td>-0.441120</td>\n",
       "      <td>-0.594371</td>\n",
       "      <td>-0.157959</td>\n",
       "      <td>-0.604804</td>\n",
       "      <td>0.065207</td>\n",
       "      <td>0.079380</td>\n",
       "      <td>0.208593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C A G Q L Y G G S Q G N L I F</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.029738</td>\n",
       "      <td>-0.364254</td>\n",
       "      <td>-0.008347</td>\n",
       "      <td>0.007682</td>\n",
       "      <td>-0.312880</td>\n",
       "      <td>0.402974</td>\n",
       "      <td>-0.163879</td>\n",
       "      <td>-0.293151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267511</td>\n",
       "      <td>0.245688</td>\n",
       "      <td>-0.081280</td>\n",
       "      <td>-0.307766</td>\n",
       "      <td>-0.095386</td>\n",
       "      <td>0.109498</td>\n",
       "      <td>-0.794303</td>\n",
       "      <td>0.025131</td>\n",
       "      <td>0.267981</td>\n",
       "      <td>0.077586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 770 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0    1         2         3         4    \\\n",
       "0  C L V G A P G Y S S A S K I I F   23 -0.634476 -0.715426 -0.112857   \n",
       "1                C A L L G R L Y F   14 -0.197206 -0.869457 -0.575098   \n",
       "2    C G T S N S G G S N Y K L T F   19 -0.356926 -0.407020  0.011429   \n",
       "3            C A E S K E G K L I F   25 -0.119118 -0.653685 -0.765995   \n",
       "4    C A G Q L Y G G S Q G N L I F   20 -0.029738 -0.364254 -0.008347   \n",
       "\n",
       "        5         6         7         8         9    ...       760       761  \\\n",
       "0 -0.026188 -0.163004  0.403640 -0.354486 -0.028810  ...  0.525054 -0.023938   \n",
       "1 -0.589052  0.364810  0.425240 -0.285844 -0.439713  ...  0.448100 -0.214829   \n",
       "2  0.016217  0.150756  0.267557 -0.530167 -0.358644  ...  0.266957 -0.431619   \n",
       "3  0.080028  0.234760  0.119031 -0.130814 -0.172284  ...  0.301340 -0.249289   \n",
       "4  0.007682 -0.312880  0.402974 -0.163879 -0.293151  ...  0.267511  0.245688   \n",
       "\n",
       "        762       763       764       765       766       767       768  \\\n",
       "0  0.282135 -0.311814  0.185906 -0.352735 -0.448487  0.025638  0.497169   \n",
       "1 -0.188320 -0.257455 -0.381339  0.370652 -0.898810 -0.381585  0.596959   \n",
       "2  0.063431 -0.255619 -0.081371 -0.068055 -0.308897 -0.062996  0.249711   \n",
       "3  0.098097 -0.441120 -0.594371 -0.157959 -0.604804  0.065207  0.079380   \n",
       "4 -0.081280 -0.307766 -0.095386  0.109498 -0.794303  0.025131  0.267981   \n",
       "\n",
       "        769  \n",
       "0  0.047479  \n",
       "1  0.254778  \n",
       "2  0.156963  \n",
       "3  0.208593  \n",
       "4  0.077586  \n",
       "\n",
       "[5 rows x 770 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av_df = av_df.reset_index(drop=True)\n",
    "df_v_emb = pd.concat([av_df, df_v_emb], axis=1, ignore_index=True)\n",
    "df_v_emb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "911c38eb-0445-49eb-87a2-4aaae839ba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_v_emb.drop([0, 1], axis=1), df_v_emb[1], test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afcbf148-c948-4d70-adfa-096c32010749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Best CV score: 0.587, best CV k: KNeighborsClassifier(n_neighbors=35, weights='distance')\n",
      "Resulting test score: 0.612\n"
     ]
    }
   ],
   "source": [
    "knn_best = train_clf(X_train, X_test, y_train, y_test, gene='v', save=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28e8db47-e803-484a-891d-67b8ed670fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Point: C A A I G G S T L G R L Y F\n",
      "Nearest Neighbors: [8983, 8099, 3221, 10331, 143]\n",
      "Nearest Labels: [17 17 17  7  3]\n",
      "Distances to Nearest Neighbors: [[1.165384   4.10142285 4.16795175 4.19935107 4.49350682 4.51299552\n",
      "  4.6255152  4.79619021 4.86849739 4.89917919 4.93790188 4.93790188\n",
      "  5.09306188 5.12971227 5.13880063 5.14726428 5.18733255 5.19217977\n",
      "  5.22167551 5.22167551 5.24774105 5.25847894 5.33857386 5.36837915\n",
      "  5.39957292 5.41882723 5.45843952 5.47608706 5.47704842 5.48595861\n",
      "  5.4871863  5.4871863  5.49239787 5.5024445  5.51526245]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akabalina/.conda/envs/ft/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "nn_v = get_nearest_neighbours('./knn_v_model.pkl', av_model, 'C A A I G G S T L G R L Y F', X_train, y_train, n_neighb=5, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4279c475-fff8-441f-9fcb-a17e98704540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TRAV29', 'TRAV29', 'TRAV29', 'TRAV19', 'TRAV13'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_enc_v.inverse_transform(y_train.loc[nn_v].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66a814a-8eee-47dd-b3e6-396b4cdcc1f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3fc549-0f93-44c2-bd97-1cf08993f800",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-ft]",
   "language": "python",
   "name": "conda-env-.conda-ft-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
