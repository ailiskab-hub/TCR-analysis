Iteration 1 of 72
   ~ Training for parameters: Hid_layer_size: [2048, 1024, 512, 256], lr: 0.0001, n_drop: 0.2, use j: True ~
Epoch 1, Loss: 5.25316858291626
Epoch 2, Loss: 4.946926116943359
Epoch 3, Loss: 4.905395030975342
Epoch 4, Loss: 4.900868892669678
Epoch 5, Loss: 4.900066375732422
Epoch 6, Loss: 4.897382736206055
Epoch 7, Loss: 4.9003095626831055
Epoch 8, Loss: 4.893712043762207
Epoch 9, Loss: 4.894876956939697
Epoch 10, Loss: 4.90094518661499
Epoch 11, Loss: 4.898746967315674
Epoch 12, Loss: 4.654598236083984
Epoch 13, Loss: 4.652285575866699
Epoch 14, Loss: 4.652760982513428
Epoch 15, Loss: 4.652998924255371
Epoch 16, Loss: 4.653707027435303
Epoch 17, Loss: 4.654427528381348
Epoch 18, Loss: 4.654375076293945
Epoch 19, Loss: 4.652786731719971
Epoch 20, Loss: 4.652189254760742
Epoch 21, Loss: 4.654144763946533
Epoch 22, Loss: 4.652002811431885
Epoch 23, Loss: 4.653295516967773
Epoch 24, Loss: 4.651752471923828
Epoch 25, Loss: 4.65234899520874
Epoch 26, Loss: 4.655662536621094
Epoch 27, Loss: 4.653176307678223
Epoch 28, Loss: 4.650988578796387
Epoch 29, Loss: 4.6501784324646
Epoch 30, Loss: 4.653374195098877
 ~ Training finished ~
 Score: V accuracy:0.6351891725622886; J accuracy: 0.9963088280529068
Iteration 2 of 72
   ~ Training for parameters: Hid_layer_size: [2048, 1024, 512, 256], lr: 0.0001, n_drop: 0.2, use j: False ~
Epoch 1, Loss: 5.041731834411621
Epoch 2, Loss: 4.910484313964844
Epoch 3, Loss: 4.903390407562256
Epoch 4, Loss: 4.900545120239258
Epoch 5, Loss: 4.901517868041992
Epoch 6, Loss: 4.900909423828125
Epoch 7, Loss: 4.904429912567139
Epoch 8, Loss: 4.899780750274658
Epoch 9, Loss: 4.893778324127197
Epoch 10, Loss: 4.779327392578125
Epoch 11, Loss: 4.778436660766602
Epoch 12, Loss: 4.774705410003662
Epoch 13, Loss: 4.7751359939575195
Epoch 14, Loss: 4.758482933044434
Epoch 15, Loss: 4.653037071228027
Epoch 16, Loss: 4.651702880859375
Epoch 17, Loss: 4.651325702667236
Epoch 18, Loss: 4.6485514640808105
Epoch 19, Loss: 4.650284767150879
Epoch 20, Loss: 4.653646945953369
Epoch 21, Loss: 4.6537556648254395
Epoch 22, Loss: 4.651006698608398
Epoch 23, Loss: 4.652163505554199
Epoch 24, Loss: 4.6507086753845215
Epoch 25, Loss: 4.403868675231934
Epoch 26, Loss: 4.407924175262451
Epoch 27, Loss: 4.403631687164307
Epoch 28, Loss: 4.403804779052734
Epoch 29, Loss: 4.403301239013672
Epoch 30, Loss: 4.404479503631592
 ~ Training finished ~
 Score: V accuracy:0.6084281759458628; J accuracy: 1.0
Iteration 3 of 72
   ~ Training for parameters: Hid_layer_size: [2048, 1024, 512, 256], lr: 0.0001, n_drop: 0.3, use j: True ~
Epoch 1, Loss: 5.155228614807129
Epoch 2, Loss: 5.02338981628418
Epoch 3, Loss: 5.022880554199219
Epoch 4, Loss: 5.043835639953613
Epoch 5, Loss: 5.019258975982666
Epoch 6, Loss: 4.902246475219727
Epoch 7, Loss: 4.898400783538818
Epoch 8, Loss: 4.901639938354492
Epoch 9, Loss: 4.902583122253418
Epoch 10, Loss: 4.903995513916016
Epoch 11, Loss: 4.903757095336914
Epoch 12, Loss: 4.90246057510376
Epoch 13, Loss: 4.911605358123779
Epoch 14, Loss: 4.898995399475098
Epoch 15, Loss: 4.896334648132324
Epoch 16, Loss: 4.901212215423584
Epoch 17, Loss: 4.900539398193359
Epoch 18, Loss: 4.901058673858643
Epoch 19, Loss: 4.9034528732299805
Epoch 20, Loss: 4.8890910148620605
Epoch 21, Loss: 4.776791572570801
Epoch 22, Loss: 4.794119834899902
Epoch 23, Loss: 4.779970645904541
Epoch 24, Loss: 4.776423454284668
Epoch 25, Loss: 4.776305198669434
Epoch 26, Loss: 4.78084659576416
Epoch 27, Loss: 4.777411937713623
Epoch 28, Loss: 4.775830268859863
Epoch 29, Loss: 4.777759552001953
Epoch 30, Loss: 4.776277542114258
 ~ Training finished ~
 Score: V accuracy:0.4743155952014765; J accuracy: 1.0
Iteration 4 of 72
   ~ Training for parameters: Hid_layer_size: [2048, 1024, 512, 256], lr: 0.0001, n_drop: 0.3, use j: False ~
Epoch 1, Loss: 5.148058891296387
Epoch 2, Loss: 5.020934104919434
Epoch 3, Loss: 4.906268119812012
Epoch 4, Loss: 4.902005672454834
Epoch 5, Loss: 4.903153419494629
Epoch 6, Loss: 4.902493953704834
Epoch 7, Loss: 4.900966644287109
Epoch 8, Loss: 4.901180744171143
Epoch 9, Loss: 4.898589134216309
Epoch 10, Loss: 4.8997416496276855
Epoch 11, Loss: 4.901238441467285
Epoch 12, Loss: 4.89719295501709
Epoch 13, Loss: 4.789338111877441
Epoch 14, Loss: 4.777255535125732
Epoch 15, Loss: 4.774874687194824
Epoch 16, Loss: 4.771726608276367
Epoch 17, Loss: 4.773958206176758
Epoch 18, Loss: 4.772443771362305
Epoch 19, Loss: 4.774083137512207
Epoch 20, Loss: 4.773097038269043
Epoch 21, Loss: 4.769876480102539
Epoch 22, Loss: 4.774273872375488
Epoch 23, Loss: 4.7717604637146
Epoch 24, Loss: 4.772835731506348
Epoch 25, Loss: 4.775144100189209
Epoch 26, Loss: 4.77158260345459
Epoch 27, Loss: 4.655768394470215
Epoch 28, Loss: 4.653849124908447
Epoch 29, Loss: 4.652040004730225
Epoch 30, Loss: 4.652251243591309
 ~ Training finished ~
 Score: V accuracy:0.478929560135343; J accuracy: 1.0
Iteration 5 of 72
   ~ Training for parameters: Hid_layer_size: [2048, 1024, 512, 256], lr: 0.0001, n_drop: 0.4, use j: True ~
Epoch 1, Loss: 5.030215263366699
Epoch 2, Loss: 5.026458263397217
Epoch 3, Loss: 5.026859760284424
Epoch 4, Loss: 4.906625270843506
Epoch 5, Loss: 4.905172824859619
Epoch 6, Loss: 4.912436008453369
Epoch 7, Loss: 4.903295040130615
Epoch 8, Loss: 4.903710842132568
Epoch 9, Loss: 4.903262138366699
Epoch 10, Loss: 4.904139518737793
Epoch 11, Loss: 4.90289306640625
Epoch 12, Loss: 4.904997825622559
Epoch 13, Loss: 4.9000325202941895
Epoch 14, Loss: 4.898323059082031
Epoch 15, Loss: 4.901710510253906
Epoch 16, Loss: 4.904567718505859
Epoch 17, Loss: 4.9019317626953125
Epoch 18, Loss: 4.905538082122803
Epoch 19, Loss: 4.904009819030762
Epoch 20, Loss: 4.903111457824707
Epoch 21, Loss: 4.900102138519287
Epoch 22, Loss: 4.903914451599121
Epoch 23, Loss: 4.784682750701904
Epoch 24, Loss: 4.780231475830078
Epoch 25, Loss: 4.778801441192627
Epoch 26, Loss: 4.779971599578857
Epoch 27, Loss: 4.780547618865967
Epoch 28, Loss: 4.778311252593994
Epoch 29, Loss: 4.779391288757324
Epoch 30, Loss: 4.778436660766602
 ~ Training finished ~
 Score: V accuracy:0.5096893263611196; J accuracy: 1.0
Iteration 6 of 72
   ~ Training for parameters: Hid_layer_size: [2048, 1024, 512, 256], lr: 0.0001, n_drop: 0.4, use j: False ~
Epoch 1, Loss: 5.181426048278809
Epoch 2, Loss: 4.8972697257995605
Epoch 3, Loss: 4.906357765197754
Epoch 4, Loss: 4.883847236633301
Epoch 5, Loss: 4.770680904388428
Epoch 6, Loss: 4.714644432067871
Epoch 7, Loss: 4.651309967041016
Epoch 8, Loss: 4.652286052703857
Epoch 9, Loss: 4.6520490646362305
Epoch 10, Loss: 4.530723571777344
Epoch 11, Loss: 4.528643608093262
Epoch 12, Loss: 4.530908107757568
Epoch 13, Loss: 4.531006813049316
Epoch 14, Loss: 4.529309272766113
Epoch 15, Loss: 4.527807712554932
Epoch 16, Loss: 4.530344009399414
Epoch 17, Loss: 4.529670715332031
Epoch 18, Loss: 4.525730609893799
Epoch 19, Loss: 4.52934455871582
Epoch 20, Loss: 4.52728271484375
Epoch 21, Loss: 4.407129287719727
Epoch 22, Loss: 4.404480934143066
Epoch 23, Loss: 4.404585838317871
Epoch 24, Loss: 4.405884742736816
Epoch 25, Loss: 4.404374122619629
Epoch 26, Loss: 4.4045891761779785
Epoch 27, Loss: 4.405317783355713
Epoch 28, Loss: 4.3520002365112305
Epoch 29, Loss: 4.283665180206299
Epoch 30, Loss: 4.280946731567383
 ~ Training finished ~
 Score: V accuracy:0.5739772377729929; J accuracy: 1.0
Iteration 7 of 72
   ~ Training for parameters: Hid_layer_size: [2048, 1024, 512, 256], lr: 1e-05, n_drop: 0.2, use j: True ~
Epoch 1, Loss: 5.008151054382324
Epoch 2, Loss: 4.917056083679199
Epoch 3, Loss: 4.782397747039795
Epoch 4, Loss: 4.662771701812744
Epoch 5, Loss: 4.662535190582275
Epoch 6, Loss: 4.663876533508301
Epoch 7, Loss: 4.6539435386657715
Epoch 8, Loss: 4.653277397155762
Epoch 9, Loss: 4.653585910797119
Epoch 10, Loss: 4.65097713470459
Epoch 11, Loss: 4.652976989746094
Epoch 12, Loss: 4.652546405792236
Epoch 13, Loss: 4.652139663696289
Epoch 14, Loss: 4.529827117919922
Epoch 15, Loss: 4.52949333190918
Epoch 16, Loss: 4.530033111572266
Epoch 17, Loss: 4.5275654792785645
Epoch 18, Loss: 4.527493000030518
Epoch 19, Loss: 4.527534484863281
Epoch 20, Loss: 4.526069164276123
Epoch 21, Loss: 4.527580261230469
Epoch 22, Loss: 4.485461711883545
Epoch 23, Loss: 4.403602123260498
Epoch 24, Loss: 4.404096603393555
Epoch 25, Loss: 4.401884078979492
Epoch 26, Loss: 4.403510093688965
Epoch 27, Loss: 4.403375625610352
Epoch 28, Loss: 4.402745723724365
Epoch 29, Loss: 4.402473449707031
Epoch 30, Loss: 4.403428077697754
 ~ Training finished ~
 Score: V accuracy:0.5758228237465395; J accuracy: 1.0
Iteration 8 of 72
   ~ Training for parameters: Hid_layer_size: [2048, 1024, 512, 256], lr: 1e-05, n_drop: 0.2, use j: False ~
Epoch 1, Loss: 5.249113082885742
Epoch 2, Loss: 5.09237813949585
Epoch 3, Loss: 5.0300397872924805
Epoch 4, Loss: 4.905686855316162
Epoch 5, Loss: 4.782345294952393
Epoch 6, Loss: 4.664710998535156
Epoch 7, Loss: 4.55377197265625
Epoch 8, Loss: 4.540358543395996
Epoch 9, Loss: 4.530120849609375
Epoch 10, Loss: 4.532216548919678
Epoch 11, Loss: 4.5298919677734375
Epoch 12, Loss: 4.54451847076416
Epoch 13, Loss: 4.529069423675537
Epoch 14, Loss: 4.529669284820557
Epoch 15, Loss: 4.528499603271484
Epoch 16, Loss: 4.5290069580078125
Epoch 17, Loss: 4.528185844421387
Epoch 18, Loss: 4.526318073272705
Epoch 19, Loss: 4.515013694763184
Epoch 20, Loss: 4.403758525848389
Epoch 21, Loss: 4.405440330505371
Epoch 22, Loss: 4.403571605682373
Epoch 23, Loss: 4.401643753051758
Epoch 24, Loss: 4.402223587036133
Epoch 25, Loss: 4.401919841766357
Epoch 26, Loss: 4.403294563293457
Epoch 27, Loss: 4.401918411254883
Epoch 28, Loss: 4.403306484222412
Epoch 29, Loss: 4.401501178741455
Epoch 30, Loss: 4.401025772094727
 ~ Training finished ~
 Score: V accuracy:0.5226084281759459; J accuracy: 1.0
Iteration 9 of 72
   ~ Training for parameters: Hid_layer_size: [2048, 1024, 512, 256], lr: 1e-05, n_drop: 0.3, use j: True ~
Epoch 1, Loss: 5.3617448806762695
Epoch 2, Loss: 5.046916961669922
Epoch 3, Loss: 4.909604072570801
Epoch 4, Loss: 4.901920795440674
Epoch 5, Loss: 4.8953857421875
Epoch 6, Loss: 4.7842793464660645
Epoch 7, Loss: 4.77971076965332
Epoch 8, Loss: 4.775930404663086
Epoch 9, Loss: 4.781874656677246
Epoch 10, Loss: 4.775795936584473
Epoch 11, Loss: 4.778913497924805
Epoch 12, Loss: 4.843873023986816
Epoch 13, Loss: 4.775041580200195
Epoch 14, Loss: 4.774703025817871
Epoch 15, Loss: 4.778502941131592
Epoch 16, Loss: 4.776707172393799
Epoch 17, Loss: 4.7783427238464355
Epoch 18, Loss: 4.772308349609375
Epoch 19, Loss: 4.771439552307129
Epoch 20, Loss: 4.656400203704834
Epoch 21, Loss: 4.534293174743652
Epoch 22, Loss: 4.530745506286621
Epoch 23, Loss: 4.542668342590332
Epoch 24, Loss: 4.530900001525879
Epoch 25, Loss: 4.527771949768066
Epoch 26, Loss: 4.536808490753174
Epoch 27, Loss: 4.529423713684082
Epoch 28, Loss: 4.526243209838867
Epoch 29, Loss: 4.526318073272705
Epoch 30, Loss: 4.526454448699951
 ~ Training finished ~
 Score: V accuracy:0.5207628422023992; J accuracy: 1.0
Iteration 10 of 72
   ~ Training for parameters: Hid_layer_size: [2048, 1024, 512, 256], lr: 1e-05, n_drop: 0.3, use j: False ~
Epoch 1, Loss: 5.294750213623047
Epoch 2, Loss: 5.151670455932617
Epoch 3, Loss: 5.0737528800964355
Epoch 4, Loss: 5.039204120635986
Epoch 5, Loss: 5.027544975280762
Epoch 6, Loss: 5.027431011199951
Epoch 7, Loss: 5.011596202850342
Epoch 8, Loss: 4.941652297973633
Epoch 9, Loss: 4.902753829956055
Epoch 10, Loss: 4.913962364196777
Epoch 11, Loss: 4.890787124633789
Epoch 12, Loss: 4.835810661315918
Epoch 13, Loss: 4.788472652435303
Epoch 14, Loss: 4.78146505355835
Epoch 15, Loss: 4.775273323059082
Epoch 16, Loss: 4.777200698852539
Epoch 17, Loss: 4.777017116546631
Epoch 18, Loss: 4.777562141418457
Epoch 19, Loss: 4.77720832824707
Epoch 20, Loss: 4.777238368988037
Epoch 21, Loss: 4.777537822723389
Epoch 22, Loss: 4.774720668792725
Epoch 23, Loss: 4.774692535400391
Epoch 24, Loss: 4.771149635314941
Epoch 25, Loss: 4.773547172546387
Epoch 26, Loss: 4.772430419921875
Epoch 27, Loss: 4.772191047668457
Epoch 28, Loss: 4.7713751792907715
Epoch 29, Loss: 4.771262168884277
Epoch 30, Loss: 4.672416687011719
 ~ Training finished ~
 Score: V accuracy:0.4835435250692095; J accuracy: 1.0
Iteration 11 of 72
   ~ Training for parameters: Hid_layer_size: [2048, 1024, 512, 256], lr: 1e-05, n_drop: 0.4, use j: True ~
Epoch 1, Loss: 5.391059875488281
Epoch 2, Loss: 5.17341423034668
Epoch 3, Loss: 5.15639591217041
Epoch 4, Loss: 5.150382995605469
Epoch 5, Loss: 5.1516218185424805
Epoch 6, Loss: 5.146381378173828
Epoch 7, Loss: 5.154986381530762
Epoch 8, Loss: 5.023754119873047
Epoch 9, Loss: 5.025871276855469
Epoch 10, Loss: 4.956995010375977
Epoch 11, Loss: 4.903238296508789
Epoch 12, Loss: 4.903817653656006
Epoch 13, Loss: 4.905106067657471
Epoch 14, Loss: 4.906793594360352
Epoch 15, Loss: 4.905113220214844
Epoch 16, Loss: 4.906513214111328
Epoch 17, Loss: 4.906159400939941
Epoch 18, Loss: 4.902238845825195
Epoch 19, Loss: 4.9051923751831055
Epoch 20, Loss: 4.863221645355225
Epoch 21, Loss: 4.791968822479248
Epoch 22, Loss: 4.777141571044922
Epoch 23, Loss: 4.774190425872803
Epoch 24, Loss: 4.773090839385986
Epoch 25, Loss: 4.776484489440918
Epoch 26, Loss: 4.777763843536377
Epoch 27, Loss: 4.772425651550293
Epoch 28, Loss: 4.655879974365234
Epoch 29, Loss: 4.653473854064941
Epoch 30, Loss: 4.64658784866333
 ~ Training finished ~
 Score: V accuracy:0.4463242079360197; J accuracy: 1.0
Iteration 12 of 72
   ~ Training for parameters: Hid_layer_size: [2048, 1024, 512, 256], lr: 1e-05, n_drop: 0.4, use j: False ~
Epoch 1, Loss: 5.355704307556152
Epoch 2, Loss: 5.208076000213623
Epoch 3, Loss: 5.14475154876709
Epoch 4, Loss: 5.152985572814941
Epoch 5, Loss: 5.149652004241943
Epoch 6, Loss: 5.148532390594482
Epoch 7, Loss: 5.008969306945801
Epoch 8, Loss: 4.942972183227539
Epoch 9, Loss: 4.915870189666748
Epoch 10, Loss: 4.906741142272949
Epoch 11, Loss: 4.905898094177246
Epoch 12, Loss: 4.913847923278809
Epoch 13, Loss: 4.9014692306518555
Epoch 14, Loss: 4.8994550704956055
Epoch 15, Loss: 4.907520771026611
Epoch 16, Loss: 4.898837566375732
Epoch 17, Loss: 4.898957252502441
Epoch 18, Loss: 4.656156539916992
Epoch 19, Loss: 4.651230812072754
Epoch 20, Loss: 4.644450664520264
Epoch 21, Loss: 4.542281150817871
Epoch 22, Loss: 4.538050174713135
Epoch 23, Loss: 4.526510238647461
Epoch 24, Loss: 4.528773307800293
Epoch 25, Loss: 4.440001010894775
Epoch 26, Loss: 4.419373512268066
Epoch 27, Loss: 4.406075477600098
Epoch 28, Loss: 4.404109954833984
Epoch 29, Loss: 4.404275894165039
Epoch 30, Loss: 4.389439582824707
 ~ Training finished ~
 Score: V accuracy:0.5324515533681944; J accuracy: 1.0
Iteration 13 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512], lr: 0.0001, n_drop: 0.2, use j: True ~
Epoch 1, Loss: 4.904457092285156
Epoch 2, Loss: 4.807251930236816
Epoch 3, Loss: 4.7746992111206055
Epoch 4, Loss: 4.771424770355225
Epoch 5, Loss: 4.771662712097168
Epoch 6, Loss: 4.770779609680176
Epoch 7, Loss: 4.768716812133789
Epoch 8, Loss: 4.7694220542907715
Epoch 9, Loss: 4.769123077392578
Epoch 10, Loss: 4.646111965179443
Epoch 11, Loss: 4.404815673828125
Epoch 12, Loss: 4.4047441482543945
Epoch 13, Loss: 4.400432586669922
Epoch 14, Loss: 4.399600028991699
Epoch 15, Loss: 4.279015064239502
Epoch 16, Loss: 4.2769269943237305
Epoch 17, Loss: 4.276397705078125
Epoch 18, Loss: 4.278943061828613
Epoch 19, Loss: 4.278266429901123
Epoch 20, Loss: 4.277441024780273
Epoch 21, Loss: 4.277247428894043
Epoch 22, Loss: 4.276501178741455
Epoch 23, Loss: 4.278450012207031
Epoch 24, Loss: 4.277319431304932
Epoch 25, Loss: 4.277120113372803
Epoch 26, Loss: 4.2779741287231445
Epoch 27, Loss: 4.278604507446289
Epoch 28, Loss: 4.280771732330322
Epoch 29, Loss: 4.277240753173828
Epoch 30, Loss: 4.277719974517822
 ~ Training finished ~
 Score: V accuracy:0.7785296831744078; J accuracy: 1.0
Iteration 14 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512], lr: 0.0001, n_drop: 0.2, use j: False ~
Epoch 1, Loss: 4.656518459320068
Epoch 2, Loss: 4.651185035705566
Epoch 3, Loss: 4.649813652038574
Epoch 4, Loss: 4.53011417388916
Epoch 5, Loss: 4.403154373168945
Epoch 6, Loss: 4.401783466339111
Epoch 7, Loss: 4.399963855743408
Epoch 8, Loss: 4.399676322937012
Epoch 9, Loss: 4.4043402671813965
Epoch 10, Loss: 4.399694442749023
Epoch 11, Loss: 4.399981498718262
Epoch 12, Loss: 4.39919900894165
Epoch 13, Loss: 4.278805732727051
Epoch 14, Loss: 4.276723861694336
Epoch 15, Loss: 4.276289939880371
Epoch 16, Loss: 4.280325889587402
Epoch 17, Loss: 4.280507564544678
Epoch 18, Loss: 4.281010150909424
Epoch 19, Loss: 4.279417514801025
Epoch 20, Loss: 4.279322147369385
Epoch 21, Loss: 4.280055046081543
Epoch 22, Loss: 4.277677536010742
Epoch 23, Loss: 4.278628349304199
Epoch 24, Loss: 4.2788238525390625
Epoch 25, Loss: 4.406651020050049
Epoch 26, Loss: 4.281361103057861
Epoch 27, Loss: 4.279400825500488
Epoch 28, Loss: 4.279806137084961
Epoch 29, Loss: 4.279940128326416
Epoch 30, Loss: 4.280210971832275
 ~ Training finished ~
 Score: V accuracy:0.7865272223931098; J accuracy: 1.0
Iteration 15 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512], lr: 0.0001, n_drop: 0.3, use j: True ~
Epoch 1, Loss: 4.905066967010498
Epoch 2, Loss: 4.902441024780273
Epoch 3, Loss: 4.775228500366211
Epoch 4, Loss: 4.773042678833008
Epoch 5, Loss: 4.77128267288208
Epoch 6, Loss: 4.768440246582031
Epoch 7, Loss: 4.768454074859619
Epoch 8, Loss: 4.769018173217773
Epoch 9, Loss: 4.769099235534668
Epoch 10, Loss: 4.769282341003418
Epoch 11, Loss: 4.651297569274902
Epoch 12, Loss: 4.64698600769043
Epoch 13, Loss: 4.404024600982666
Epoch 14, Loss: 4.402780532836914
Epoch 15, Loss: 4.40275764465332
Epoch 16, Loss: 4.403063774108887
Epoch 17, Loss: 4.4010725021362305
Epoch 18, Loss: 4.401074409484863
Epoch 19, Loss: 4.400358200073242
Epoch 20, Loss: 4.402705669403076
Epoch 21, Loss: 4.400591850280762
Epoch 22, Loss: 4.278010368347168
Epoch 23, Loss: 4.277833938598633
Epoch 24, Loss: 4.155355453491211
Epoch 25, Loss: 4.155275344848633
Epoch 26, Loss: 4.154629707336426
Epoch 27, Loss: 4.154746055603027
Epoch 28, Loss: 4.154906272888184
Epoch 29, Loss: 4.155684471130371
Epoch 30, Loss: 4.157652854919434
 ~ Training finished ~
 Score: V accuracy:0.7840664410950476; J accuracy: 1.0
Iteration 16 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512], lr: 0.0001, n_drop: 0.3, use j: False ~
Epoch 1, Loss: 4.657315254211426
Epoch 2, Loss: 4.531257152557373
Epoch 3, Loss: 4.527215480804443
Epoch 4, Loss: 4.402790069580078
Epoch 5, Loss: 4.405003547668457
Epoch 6, Loss: 4.400678634643555
Epoch 7, Loss: 4.400162696838379
Epoch 8, Loss: 4.399850845336914
Epoch 9, Loss: 4.3996734619140625
Epoch 10, Loss: 4.399599075317383
Epoch 11, Loss: 4.400824069976807
Epoch 12, Loss: 4.405646324157715
Epoch 13, Loss: 4.402128219604492
Epoch 14, Loss: 4.280918121337891
Epoch 15, Loss: 4.280269622802734
Epoch 16, Loss: 4.27699089050293
Epoch 17, Loss: 4.278726577758789
Epoch 18, Loss: 4.2773027420043945
Epoch 19, Loss: 4.278286457061768
Epoch 20, Loss: 4.154158115386963
Epoch 21, Loss: 4.155956268310547
Epoch 22, Loss: 4.154469966888428
Epoch 23, Loss: 4.1558709144592285
Epoch 24, Loss: 4.155806064605713
Epoch 25, Loss: 4.155751705169678
Epoch 26, Loss: 4.154563903808594
Epoch 27, Loss: 4.154651165008545
Epoch 28, Loss: 4.15604305267334
Epoch 29, Loss: 4.157182216644287
Epoch 30, Loss: 4.158685684204102
 ~ Training finished ~
 Score: V accuracy:0.7776068901876346; J accuracy: 1.0
Iteration 17 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512], lr: 0.0001, n_drop: 0.4, use j: True ~
Epoch 1, Loss: 4.912369251251221
Epoch 2, Loss: 4.902665138244629
Epoch 3, Loss: 4.772100448608398
Epoch 4, Loss: 4.774414539337158
Epoch 5, Loss: 4.662682056427002
Epoch 6, Loss: 4.768872261047363
Epoch 7, Loss: 4.647226810455322
Epoch 8, Loss: 4.647134780883789
Epoch 9, Loss: 4.646967887878418
Epoch 10, Loss: 4.655168056488037
Epoch 11, Loss: 4.653106212615967
Epoch 12, Loss: 4.649314880371094
Epoch 13, Loss: 4.647291660308838
Epoch 14, Loss: 4.645945072174072
Epoch 15, Loss: 4.649579048156738
Epoch 16, Loss: 4.646806240081787
Epoch 17, Loss: 4.64702844619751
Epoch 18, Loss: 4.645906925201416
Epoch 19, Loss: 4.590030670166016
Epoch 20, Loss: 4.526486873626709
Epoch 21, Loss: 4.279767990112305
Epoch 22, Loss: 4.278576850891113
Epoch 23, Loss: 4.2787699699401855
Epoch 24, Loss: 4.27725887298584
Epoch 25, Loss: 4.278077125549316
Epoch 26, Loss: 4.279590606689453
Epoch 27, Loss: 4.28082275390625
Epoch 28, Loss: 4.279887676239014
Epoch 29, Loss: 4.280052661895752
Epoch 30, Loss: 4.279097080230713
 ~ Training finished ~
 Score: V accuracy:0.7739157182405414; J accuracy: 1.0
Iteration 18 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512], lr: 0.0001, n_drop: 0.4, use j: False ~
Epoch 1, Loss: 5.147050857543945
Epoch 2, Loss: 4.909539222717285
Epoch 3, Loss: 4.902400493621826
Epoch 4, Loss: 4.895195007324219
Epoch 5, Loss: 4.773916244506836
Epoch 6, Loss: 4.771100997924805
Epoch 7, Loss: 4.7702813148498535
Epoch 8, Loss: 4.410088539123535
Epoch 9, Loss: 4.403648376464844
Epoch 10, Loss: 4.401150703430176
Epoch 11, Loss: 4.4011030197143555
Epoch 12, Loss: 4.403268337249756
Epoch 13, Loss: 4.400315761566162
Epoch 14, Loss: 4.404975414276123
Epoch 15, Loss: 4.4029083251953125
Epoch 16, Loss: 4.405670642852783
Epoch 17, Loss: 4.279989242553711
Epoch 18, Loss: 4.280057907104492
Epoch 19, Loss: 4.278947830200195
Epoch 20, Loss: 4.278617858886719
Epoch 21, Loss: 4.279151916503906
Epoch 22, Loss: 4.283923149108887
Epoch 23, Loss: 4.279663562774658
Epoch 24, Loss: 4.278730869293213
Epoch 25, Loss: 4.278517723083496
Epoch 26, Loss: 4.277666091918945
Epoch 27, Loss: 4.277163505554199
Epoch 28, Loss: 4.279615879058838
Epoch 29, Loss: 4.279211521148682
Epoch 30, Loss: 4.2793426513671875
 ~ Training finished ~
 Score: V accuracy:0.7739157182405414; J accuracy: 1.0
Iteration 19 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512], lr: 1e-05, n_drop: 0.2, use j: True ~
Epoch 1, Loss: 5.318162441253662
Epoch 2, Loss: 5.053824424743652
Epoch 3, Loss: 5.009304523468018
Epoch 4, Loss: 4.915842533111572
Epoch 5, Loss: 4.910377502441406
Epoch 6, Loss: 4.904754638671875
Epoch 7, Loss: 4.903223514556885
Epoch 8, Loss: 4.903329849243164
Epoch 9, Loss: 4.902448654174805
Epoch 10, Loss: 4.7842559814453125
Epoch 11, Loss: 4.779853820800781
Epoch 12, Loss: 4.774453639984131
Epoch 13, Loss: 4.773838043212891
Epoch 14, Loss: 4.773799419403076
Epoch 15, Loss: 4.668561935424805
Epoch 16, Loss: 4.651793479919434
Epoch 17, Loss: 4.649074554443359
Epoch 18, Loss: 4.648592948913574
Epoch 19, Loss: 4.64790153503418
Epoch 20, Loss: 4.647533416748047
Epoch 21, Loss: 4.647918224334717
Epoch 22, Loss: 4.649056911468506
Epoch 23, Loss: 4.6466498374938965
Epoch 24, Loss: 4.5280914306640625
Epoch 25, Loss: 4.524115085601807
Epoch 26, Loss: 4.528459548950195
Epoch 27, Loss: 4.524521350860596
Epoch 28, Loss: 4.523282527923584
Epoch 29, Loss: 4.524120807647705
Epoch 30, Loss: 4.602234363555908
 ~ Training finished ~
 Score: V accuracy:0.5112273146724085; J accuracy: 1.0
Iteration 20 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512], lr: 1e-05, n_drop: 0.2, use j: False ~
Epoch 1, Loss: 5.173349380493164
Epoch 2, Loss: 4.803897857666016
Epoch 3, Loss: 4.683462142944336
Epoch 4, Loss: 4.664645671844482
Epoch 5, Loss: 4.658897876739502
Epoch 6, Loss: 4.654310703277588
Epoch 7, Loss: 4.615787506103516
Epoch 8, Loss: 4.542204856872559
Epoch 9, Loss: 4.530186176300049
Epoch 10, Loss: 4.5268120765686035
Epoch 11, Loss: 4.52728271484375
Epoch 12, Loss: 4.526902198791504
Epoch 13, Loss: 4.525687217712402
Epoch 14, Loss: 4.525634765625
Epoch 15, Loss: 4.525489330291748
Epoch 16, Loss: 4.525204658508301
Epoch 17, Loss: 4.403312683105469
Epoch 18, Loss: 4.401924133300781
Epoch 19, Loss: 4.402187824249268
Epoch 20, Loss: 4.401526927947998
Epoch 21, Loss: 4.402303695678711
Epoch 22, Loss: 4.400388240814209
Epoch 23, Loss: 4.401170253753662
Epoch 24, Loss: 4.4007568359375
Epoch 25, Loss: 4.399893283843994
Epoch 26, Loss: 4.400138854980469
Epoch 27, Loss: 4.40024471282959
Epoch 28, Loss: 4.401410102844238
Epoch 29, Loss: 4.402207851409912
Epoch 30, Loss: 4.402580261230469
 ~ Training finished ~
 Score: V accuracy:0.6235004613964934; J accuracy: 1.0
Iteration 21 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512], lr: 1e-05, n_drop: 0.3, use j: True ~
Epoch 1, Loss: 5.2925825119018555
Epoch 2, Loss: 5.156030654907227
Epoch 3, Loss: 4.9373931884765625
Epoch 4, Loss: 4.913803577423096
Epoch 5, Loss: 4.910516738891602
Epoch 6, Loss: 4.916678428649902
Epoch 7, Loss: 4.789979457855225
Epoch 8, Loss: 4.783690452575684
Epoch 9, Loss: 4.781639099121094
Epoch 10, Loss: 4.77406120300293
Epoch 11, Loss: 4.777254581451416
Epoch 12, Loss: 4.7745585441589355
Epoch 13, Loss: 4.7724409103393555
Epoch 14, Loss: 4.772719383239746
Epoch 15, Loss: 4.654527187347412
Epoch 16, Loss: 4.650247573852539
Epoch 17, Loss: 4.65112829208374
Epoch 18, Loss: 4.648421287536621
Epoch 19, Loss: 4.647388458251953
Epoch 20, Loss: 4.646958351135254
Epoch 21, Loss: 4.407121658325195
Epoch 22, Loss: 4.405830383300781
Epoch 23, Loss: 4.404977321624756
Epoch 24, Loss: 4.404027462005615
Epoch 25, Loss: 4.40294075012207
Epoch 26, Loss: 4.404348850250244
Epoch 27, Loss: 4.401904106140137
Epoch 28, Loss: 4.4016242027282715
Epoch 29, Loss: 4.401913166046143
Epoch 30, Loss: 4.400970458984375
 ~ Training finished ~
 Score: V accuracy:0.6053521993232851; J accuracy: 1.0
Iteration 22 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512], lr: 1e-05, n_drop: 0.3, use j: False ~
Epoch 1, Loss: 5.001977920532227
Epoch 2, Loss: 4.921965599060059
Epoch 3, Loss: 4.6913347244262695
Epoch 4, Loss: 4.669685363769531
Epoch 5, Loss: 4.659409523010254
Epoch 6, Loss: 4.552577495574951
Epoch 7, Loss: 4.53385066986084
Epoch 8, Loss: 4.533974647521973
Epoch 9, Loss: 4.528511047363281
Epoch 10, Loss: 4.528568267822266
Epoch 11, Loss: 4.526850700378418
Epoch 12, Loss: 4.526485443115234
Epoch 13, Loss: 4.526716232299805
Epoch 14, Loss: 4.525905609130859
Epoch 15, Loss: 4.526037693023682
Epoch 16, Loss: 4.526344299316406
Epoch 17, Loss: 4.524619102478027
Epoch 18, Loss: 4.419613361358643
Epoch 19, Loss: 4.401198863983154
Epoch 20, Loss: 4.401508808135986
Epoch 21, Loss: 4.400762557983398
Epoch 22, Loss: 4.400200843811035
Epoch 23, Loss: 4.401154041290283
Epoch 24, Loss: 4.399633407592773
Epoch 25, Loss: 4.400466442108154
Epoch 26, Loss: 4.399927139282227
Epoch 27, Loss: 4.400012493133545
Epoch 28, Loss: 4.400670051574707
Epoch 29, Loss: 4.400071144104004
Epoch 30, Loss: 4.399960517883301
 ~ Training finished ~
 Score: V accuracy:0.5336819440172255; J accuracy: 1.0
Iteration 23 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512], lr: 1e-05, n_drop: 0.4, use j: True ~
Epoch 1, Loss: 5.086090564727783
Epoch 2, Loss: 4.971073627471924
Epoch 3, Loss: 4.815830230712891
Epoch 4, Loss: 4.730735778808594
Epoch 5, Loss: 4.671878814697266
Epoch 6, Loss: 4.6644182205200195
Epoch 7, Loss: 4.655807971954346
Epoch 8, Loss: 4.656845569610596
Epoch 9, Loss: 4.651711463928223
Epoch 10, Loss: 4.644710063934326
Epoch 11, Loss: 4.533961296081543
Epoch 12, Loss: 4.529120922088623
Epoch 13, Loss: 4.527255535125732
Epoch 14, Loss: 4.4130096435546875
Epoch 15, Loss: 4.41042423248291
Epoch 16, Loss: 4.403191089630127
Epoch 17, Loss: 4.403125286102295
Epoch 18, Loss: 4.404761791229248
Epoch 19, Loss: 4.402356147766113
Epoch 20, Loss: 4.403092861175537
Epoch 21, Loss: 4.402170181274414
Epoch 22, Loss: 4.401288986206055
Epoch 23, Loss: 4.400966644287109
Epoch 24, Loss: 4.400861740112305
Epoch 25, Loss: 4.401448726654053
Epoch 26, Loss: 4.402403831481934
Epoch 27, Loss: 4.302823066711426
Epoch 28, Loss: 4.281944751739502
Epoch 29, Loss: 4.28373908996582
Epoch 30, Loss: 4.280336380004883
 ~ Training finished ~
 Score: V accuracy:0.6105813595816671; J accuracy: 1.0
Iteration 24 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512], lr: 1e-05, n_drop: 0.4, use j: False ~
Epoch 1, Loss: 5.271230697631836
Epoch 2, Loss: 4.930342197418213
Epoch 3, Loss: 4.905104160308838
Epoch 4, Loss: 4.902329921722412
Epoch 5, Loss: 4.780778884887695
Epoch 6, Loss: 4.668373107910156
Epoch 7, Loss: 4.610725402832031
Epoch 8, Loss: 4.550795078277588
Epoch 9, Loss: 4.5328569412231445
Epoch 10, Loss: 4.529037952423096
Epoch 11, Loss: 4.529872417449951
Epoch 12, Loss: 4.530498504638672
Epoch 13, Loss: 4.5271172523498535
Epoch 14, Loss: 4.529168128967285
Epoch 15, Loss: 4.527442932128906
Epoch 16, Loss: 4.526464939117432
Epoch 17, Loss: 4.5265655517578125
Epoch 18, Loss: 4.525376319885254
Epoch 19, Loss: 4.524127960205078
Epoch 20, Loss: 4.523562431335449
Epoch 21, Loss: 4.529999256134033
Epoch 22, Loss: 4.525341510772705
Epoch 23, Loss: 4.525488376617432
Epoch 24, Loss: 4.525420665740967
Epoch 25, Loss: 4.5242919921875
Epoch 26, Loss: 4.523540496826172
Epoch 27, Loss: 4.524261951446533
Epoch 28, Loss: 4.416512489318848
Epoch 29, Loss: 4.347729682922363
Epoch 30, Loss: 4.281517028808594
 ~ Training finished ~
 Score: V accuracy:0.5952014764687789; J accuracy: 1.0
Iteration 25 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 256], lr: 0.0001, n_drop: 0.2, use j: True ~
Epoch 1, Loss: 4.895773887634277
Epoch 2, Loss: 4.672821521759033
Epoch 3, Loss: 4.45015811920166
Epoch 4, Loss: 4.40528678894043
Epoch 5, Loss: 4.404608726501465
Epoch 6, Loss: 4.40479040145874
Epoch 7, Loss: 4.406296253204346
Epoch 8, Loss: 4.404213905334473
Epoch 9, Loss: 4.404675006866455
Epoch 10, Loss: 4.316118240356445
Epoch 11, Loss: 4.293510437011719
Epoch 12, Loss: 4.28123664855957
Epoch 13, Loss: 4.280971527099609
Epoch 14, Loss: 4.281211853027344
Epoch 15, Loss: 4.280972480773926
Epoch 16, Loss: 4.280984878540039
Epoch 17, Loss: 4.281113147735596
Epoch 18, Loss: 4.284012317657471
Epoch 19, Loss: 4.280721187591553
Epoch 20, Loss: 4.280601501464844
Epoch 21, Loss: 4.281169414520264
Epoch 22, Loss: 4.280989646911621
Epoch 23, Loss: 4.281822204589844
Epoch 24, Loss: 4.28105354309082
Epoch 25, Loss: 4.280904293060303
Epoch 26, Loss: 4.2809553146362305
Epoch 27, Loss: 4.285918235778809
Epoch 28, Loss: 4.2808661460876465
Epoch 29, Loss: 4.279428482055664
Epoch 30, Loss: 4.279984951019287
 ~ Training finished ~
 Score: V accuracy:0.7170101507228545; J accuracy: 1.0
Iteration 26 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 256], lr: 0.0001, n_drop: 0.2, use j: False ~
Epoch 1, Loss: 5.034650802612305
Epoch 2, Loss: 4.845991134643555
Epoch 3, Loss: 4.785262584686279
Epoch 4, Loss: 4.778146266937256
Epoch 5, Loss: 4.778299331665039
Epoch 6, Loss: 4.77880859375
Epoch 7, Loss: 4.778045654296875
Epoch 8, Loss: 4.778112411499023
Epoch 9, Loss: 4.774897575378418
Epoch 10, Loss: 4.772309303283691
Epoch 11, Loss: 4.771735191345215
Epoch 12, Loss: 4.774691581726074
Epoch 13, Loss: 4.7790045738220215
Epoch 14, Loss: 4.777350425720215
Epoch 15, Loss: 4.776147842407227
Epoch 16, Loss: 4.776923179626465
Epoch 17, Loss: 4.7829132080078125
Epoch 18, Loss: 4.779236793518066
Epoch 19, Loss: 4.778125762939453
Epoch 20, Loss: 4.776088237762451
Epoch 21, Loss: 4.7317328453063965
Epoch 22, Loss: 4.653571128845215
Epoch 23, Loss: 4.660309314727783
Epoch 24, Loss: 4.655601978302002
Epoch 25, Loss: 4.654486179351807
Epoch 26, Loss: 4.406389236450195
Epoch 27, Loss: 4.406231880187988
Epoch 28, Loss: 4.405328273773193
Epoch 29, Loss: 4.405941009521484
Epoch 30, Loss: 4.4045538902282715
 ~ Training finished ~
 Score: V accuracy:0.7450015379883113; J accuracy: 1.0
Iteration 27 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 256], lr: 0.0001, n_drop: 0.3, use j: True ~
Epoch 1, Loss: 5.262628555297852
Epoch 2, Loss: 4.902773380279541
Epoch 3, Loss: 4.898336887359619
Epoch 4, Loss: 4.783252716064453
Epoch 5, Loss: 4.528044700622559
Epoch 6, Loss: 4.548035621643066
Epoch 7, Loss: 4.528686046600342
Epoch 8, Loss: 4.529984474182129
Epoch 9, Loss: 4.53292989730835
Epoch 10, Loss: 4.540989875793457
Epoch 11, Loss: 4.5301103591918945
Epoch 12, Loss: 4.526011943817139
Epoch 13, Loss: 4.447444438934326
Epoch 14, Loss: 4.2813215255737305
Epoch 15, Loss: 4.280101776123047
Epoch 16, Loss: 4.2793684005737305
Epoch 17, Loss: 4.281052112579346
Epoch 18, Loss: 4.279654026031494
Epoch 19, Loss: 4.157158374786377
Epoch 20, Loss: 4.155986785888672
Epoch 21, Loss: 4.156270503997803
Epoch 22, Loss: 4.157201766967773
Epoch 23, Loss: 4.155974388122559
Epoch 24, Loss: 4.156430721282959
Epoch 25, Loss: 4.155510902404785
Epoch 26, Loss: 4.155984401702881
Epoch 27, Loss: 4.155921936035156
Epoch 28, Loss: 4.156071662902832
Epoch 29, Loss: 4.155982971191406
Epoch 30, Loss: 4.1559739112854
 ~ Training finished ~
 Score: V accuracy:0.6887111657951399; J accuracy: 1.0
Iteration 28 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 256], lr: 0.0001, n_drop: 0.3, use j: False ~
Epoch 1, Loss: 4.834547519683838
Epoch 2, Loss: 4.659155368804932
Epoch 3, Loss: 4.654577255249023
Epoch 4, Loss: 4.66717004776001
Epoch 5, Loss: 4.6518144607543945
Epoch 6, Loss: 4.528250217437744
Epoch 7, Loss: 4.529802322387695
Epoch 8, Loss: 4.528280258178711
Epoch 9, Loss: 4.534923553466797
Epoch 10, Loss: 4.5282745361328125
Epoch 11, Loss: 4.444544315338135
Epoch 12, Loss: 4.406317234039307
Epoch 13, Loss: 4.403039932250977
Epoch 14, Loss: 4.291196346282959
Epoch 15, Loss: 4.282565116882324
Epoch 16, Loss: 4.278058052062988
Epoch 17, Loss: 4.163318157196045
Epoch 18, Loss: 4.156644821166992
Epoch 19, Loss: 4.1559834480285645
Epoch 20, Loss: 4.1561994552612305
Epoch 21, Loss: 4.155905246734619
Epoch 22, Loss: 4.154829978942871
Epoch 23, Loss: 4.154901504516602
Epoch 24, Loss: 4.161073684692383
Epoch 25, Loss: 4.156876087188721
Epoch 26, Loss: 4.155456066131592
Epoch 27, Loss: 4.155882358551025
Epoch 28, Loss: 4.155981540679932
Epoch 29, Loss: 4.15609884262085
Epoch 30, Loss: 4.158128261566162
 ~ Training finished ~
 Score: V accuracy:0.7130113811135035; J accuracy: 1.0
Iteration 29 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 256], lr: 0.0001, n_drop: 0.4, use j: True ~
Epoch 1, Loss: 4.904206275939941
Epoch 2, Loss: 4.675555229187012
Epoch 3, Loss: 4.6591949462890625
Epoch 4, Loss: 4.742214679718018
Epoch 5, Loss: 4.55091667175293
Epoch 6, Loss: 4.393690586090088
Epoch 7, Loss: 4.281431198120117
Epoch 8, Loss: 4.2788238525390625
Epoch 9, Loss: 4.2792534828186035
Epoch 10, Loss: 4.280481338500977
Epoch 11, Loss: 4.312926292419434
Epoch 12, Loss: 4.279304504394531
Epoch 13, Loss: 4.282015800476074
Epoch 14, Loss: 4.281197547912598
Epoch 15, Loss: 4.28154182434082
Epoch 16, Loss: 4.280912399291992
Epoch 17, Loss: 4.279689311981201
Epoch 18, Loss: 4.281269550323486
Epoch 19, Loss: 4.282051086425781
Epoch 20, Loss: 4.280973434448242
Epoch 21, Loss: 4.279756546020508
Epoch 22, Loss: 4.279285907745361
Epoch 23, Loss: 4.280195236206055
Epoch 24, Loss: 4.279338836669922
Epoch 25, Loss: 4.280444622039795
Epoch 26, Loss: 4.279678821563721
Epoch 27, Loss: 4.284141540527344
Epoch 28, Loss: 4.279027462005615
Epoch 29, Loss: 4.279291152954102
Epoch 30, Loss: 4.280716419219971
 ~ Training finished ~
 Score: V accuracy:0.699169486311904; J accuracy: 1.0
Iteration 30 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 256], lr: 0.0001, n_drop: 0.4, use j: False ~
Epoch 1, Loss: 4.893492698669434
Epoch 2, Loss: 4.65641975402832
Epoch 3, Loss: 4.626832485198975
Epoch 4, Loss: 4.516234874725342
Epoch 5, Loss: 4.410089492797852
Epoch 6, Loss: 4.40884256362915
Epoch 7, Loss: 4.403610706329346
Epoch 8, Loss: 4.406033039093018
Epoch 9, Loss: 4.405046463012695
Epoch 10, Loss: 4.410159587860107
Epoch 11, Loss: 4.407086372375488
Epoch 12, Loss: 4.465092182159424
Epoch 13, Loss: 4.405517101287842
Epoch 14, Loss: 4.404449462890625
Epoch 15, Loss: 4.401839256286621
Epoch 16, Loss: 4.40517520904541
Epoch 17, Loss: 4.405721187591553
Epoch 18, Loss: 4.403120994567871
Epoch 19, Loss: 4.4043073654174805
Epoch 20, Loss: 4.4077863693237305
Epoch 21, Loss: 4.405200004577637
Epoch 22, Loss: 4.404745101928711
Epoch 23, Loss: 4.403748035430908
Epoch 24, Loss: 4.52509880065918
Epoch 25, Loss: 4.404730319976807
Epoch 26, Loss: 4.405526161193848
Epoch 27, Loss: 4.405442714691162
Epoch 28, Loss: 4.405965328216553
Epoch 29, Loss: 4.405121803283691
Epoch 30, Loss: 4.4059739112854
 ~ Training finished ~
 Score: V accuracy:0.7619194094124885; J accuracy: 1.0
Iteration 31 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 256], lr: 1e-05, n_drop: 0.2, use j: True ~
Epoch 1, Loss: 5.36735725402832
Epoch 2, Loss: 5.059683322906494
Epoch 3, Loss: 5.03348445892334
Epoch 4, Loss: 4.963932991027832
Epoch 5, Loss: 4.9166579246521
Epoch 6, Loss: 4.940074920654297
Epoch 7, Loss: 4.907042026519775
Epoch 8, Loss: 4.908570766448975
Epoch 9, Loss: 4.9199538230896
Epoch 10, Loss: 4.825552463531494
Epoch 11, Loss: 4.819936275482178
Epoch 12, Loss: 4.664085865020752
Epoch 13, Loss: 4.662301540374756
Epoch 14, Loss: 4.664341926574707
Epoch 15, Loss: 4.65206241607666
Epoch 16, Loss: 4.650397300720215
Epoch 17, Loss: 4.654787063598633
Epoch 18, Loss: 4.650648593902588
Epoch 19, Loss: 4.657794952392578
Epoch 20, Loss: 4.655305862426758
Epoch 21, Loss: 4.649722576141357
Epoch 22, Loss: 4.654171466827393
Epoch 23, Loss: 4.650424003601074
Epoch 24, Loss: 4.648374557495117
Epoch 25, Loss: 4.649615287780762
Epoch 26, Loss: 4.623968601226807
Epoch 27, Loss: 4.531022071838379
Epoch 28, Loss: 4.524456024169922
Epoch 29, Loss: 4.298283100128174
Epoch 30, Loss: 4.285190105438232
 ~ Training finished ~
 Score: V accuracy:0.5868963395878192; J accuracy: 1.0
Iteration 32 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 256], lr: 1e-05, n_drop: 0.2, use j: False ~
Epoch 1, Loss: 5.305117607116699
Epoch 2, Loss: 5.1494364738464355
Epoch 3, Loss: 5.0331525802612305
Epoch 4, Loss: 5.022396087646484
Epoch 5, Loss: 5.006971836090088
Epoch 6, Loss: 4.911463260650635
Epoch 7, Loss: 4.913562297821045
Epoch 8, Loss: 4.915530204772949
Epoch 9, Loss: 4.923356533050537
Epoch 10, Loss: 4.928206920623779
Epoch 11, Loss: 4.90350341796875
Epoch 12, Loss: 4.7864460945129395
Epoch 13, Loss: 4.792327880859375
Epoch 14, Loss: 4.779275894165039
Epoch 15, Loss: 4.779534339904785
Epoch 16, Loss: 4.779752254486084
Epoch 17, Loss: 4.7762956619262695
Epoch 18, Loss: 4.784345626831055
Epoch 19, Loss: 4.684452056884766
Epoch 20, Loss: 4.662674903869629
Epoch 21, Loss: 4.668381690979004
Epoch 22, Loss: 4.655845642089844
Epoch 23, Loss: 4.648813724517822
Epoch 24, Loss: 4.656634330749512
Epoch 25, Loss: 4.650559902191162
Epoch 26, Loss: 4.649600028991699
Epoch 27, Loss: 4.652895450592041
Epoch 28, Loss: 4.64914608001709
Epoch 29, Loss: 4.647515296936035
Epoch 30, Loss: 4.648550510406494
 ~ Training finished ~
 Score: V accuracy:0.5481390341433405; J accuracy: 1.0
Iteration 33 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 256], lr: 1e-05, n_drop: 0.3, use j: True ~
Epoch 1, Loss: 5.247097969055176
Epoch 2, Loss: 5.00630521774292
Epoch 3, Loss: 4.9202656745910645
Epoch 4, Loss: 4.894427299499512
Epoch 5, Loss: 4.901944637298584
Epoch 6, Loss: 4.793966293334961
Epoch 7, Loss: 4.769434928894043
Epoch 8, Loss: 4.680953502655029
Epoch 9, Loss: 4.663037300109863
Epoch 10, Loss: 4.658873558044434
Epoch 11, Loss: 4.660346031188965
Epoch 12, Loss: 4.65230655670166
Epoch 13, Loss: 4.673235893249512
Epoch 14, Loss: 4.657998085021973
Epoch 15, Loss: 4.608375549316406
Epoch 16, Loss: 4.579161643981934
Epoch 17, Loss: 4.554623126983643
Epoch 18, Loss: 4.545280456542969
Epoch 19, Loss: 4.531160354614258
Epoch 20, Loss: 4.530651569366455
Epoch 21, Loss: 4.537913799285889
Epoch 22, Loss: 4.531737327575684
Epoch 23, Loss: 4.52940034866333
Epoch 24, Loss: 4.528420448303223
Epoch 25, Loss: 4.529693126678467
Epoch 26, Loss: 4.5371809005737305
Epoch 27, Loss: 4.5312604904174805
Epoch 28, Loss: 4.527349472045898
Epoch 29, Loss: 4.5331878662109375
Epoch 30, Loss: 4.525917053222656
 ~ Training finished ~
 Score: V accuracy:0.5970470624423254; J accuracy: 1.0
Iteration 34 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 256], lr: 1e-05, n_drop: 0.3, use j: False ~
Epoch 1, Loss: 5.106902122497559
Epoch 2, Loss: 4.919764041900635
Epoch 3, Loss: 4.922797203063965
Epoch 4, Loss: 4.807614326477051
Epoch 5, Loss: 4.792695999145508
Epoch 6, Loss: 4.685624122619629
Epoch 7, Loss: 4.677958011627197
Epoch 8, Loss: 4.669210433959961
Epoch 9, Loss: 4.65696382522583
Epoch 10, Loss: 4.680732727050781
Epoch 11, Loss: 4.654973983764648
Epoch 12, Loss: 4.652749061584473
Epoch 13, Loss: 4.653871536254883
Epoch 14, Loss: 4.652684688568115
Epoch 15, Loss: 4.653794288635254
Epoch 16, Loss: 4.651270866394043
Epoch 17, Loss: 4.653619289398193
Epoch 18, Loss: 4.654579162597656
Epoch 19, Loss: 4.540537357330322
Epoch 20, Loss: 4.5307769775390625
Epoch 21, Loss: 4.595335960388184
Epoch 22, Loss: 4.529747009277344
Epoch 23, Loss: 4.5311126708984375
Epoch 24, Loss: 4.507747173309326
Epoch 25, Loss: 4.426839828491211
Epoch 26, Loss: 4.407593727111816
Epoch 27, Loss: 4.421408176422119
Epoch 28, Loss: 4.4091691970825195
Epoch 29, Loss: 4.4091691970825195
Epoch 30, Loss: 4.403459548950195
 ~ Training finished ~
 Score: V accuracy:0.5226084281759459; J accuracy: 1.0
Iteration 35 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 256], lr: 1e-05, n_drop: 0.4, use j: True ~
Epoch 1, Loss: 5.331615924835205
Epoch 2, Loss: 5.256097793579102
Epoch 3, Loss: 5.199997901916504
Epoch 4, Loss: 5.101505279541016
Epoch 5, Loss: 5.031144142150879
Epoch 6, Loss: 5.0442728996276855
Epoch 7, Loss: 5.078634738922119
Epoch 8, Loss: 5.027602672576904
Epoch 9, Loss: 5.0106706619262695
Epoch 10, Loss: 5.0127644538879395
Epoch 11, Loss: 4.951349258422852
Epoch 12, Loss: 4.924884796142578
Epoch 13, Loss: 4.93006706237793
Epoch 14, Loss: 4.915130138397217
Epoch 15, Loss: 5.003993988037109
Epoch 16, Loss: 4.89986515045166
Epoch 17, Loss: 4.936158180236816
Epoch 18, Loss: 4.899503707885742
Epoch 19, Loss: 4.900631904602051
Epoch 20, Loss: 4.8973774909973145
Epoch 21, Loss: 4.930062770843506
Epoch 22, Loss: 4.862061500549316
Epoch 23, Loss: 4.862723350524902
Epoch 24, Loss: 4.78203010559082
Epoch 25, Loss: 4.901340484619141
Epoch 26, Loss: 4.831620216369629
Epoch 27, Loss: 4.776357650756836
Epoch 28, Loss: 4.776320457458496
Epoch 29, Loss: 4.796702861785889
Epoch 30, Loss: 4.783064365386963
 ~ Training finished ~
 Score: V accuracy:0.5223008305136881; J accuracy: 1.0
Iteration 36 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 256], lr: 1e-05, n_drop: 0.4, use j: False ~
Epoch 1, Loss: 5.3881659507751465
Epoch 2, Loss: 5.212431907653809
Epoch 3, Loss: 5.16495418548584
Epoch 4, Loss: 5.13654088973999
Epoch 5, Loss: 5.123401641845703
Epoch 6, Loss: 5.142037391662598
Epoch 7, Loss: 5.13623046875
Epoch 8, Loss: 5.068935394287109
Epoch 9, Loss: 5.053389549255371
Epoch 10, Loss: 5.060791969299316
Epoch 11, Loss: 5.037269592285156
Epoch 12, Loss: 4.907559394836426
Epoch 13, Loss: 4.9156880378723145
Epoch 14, Loss: 4.731593132019043
Epoch 15, Loss: 4.660797595977783
Epoch 16, Loss: 4.661716461181641
Epoch 17, Loss: 4.675123691558838
Epoch 18, Loss: 4.684720039367676
Epoch 19, Loss: 4.6961164474487305
Epoch 20, Loss: 4.662294387817383
Epoch 21, Loss: 4.662237167358398
Epoch 22, Loss: 4.655811786651611
Epoch 23, Loss: 4.665963172912598
Epoch 24, Loss: 4.657957553863525
Epoch 25, Loss: 4.654882907867432
Epoch 26, Loss: 4.6547675132751465
Epoch 27, Loss: 4.673074245452881
Epoch 28, Loss: 4.651906967163086
Epoch 29, Loss: 4.654096603393555
Epoch 30, Loss: 4.650692462921143
 ~ Training finished ~
 Score: V accuracy:0.5687480775146109; J accuracy: 1.0
Iteration 37 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 256, 128], lr: 0.0001, n_drop: 0.2, use j: True ~
Epoch 1, Loss: 5.147562026977539
Epoch 2, Loss: 5.148539066314697
Epoch 3, Loss: 5.150601387023926
Epoch 4, Loss: 5.027139186859131
Epoch 5, Loss: 5.028824329376221
Epoch 6, Loss: 5.02786111831665
Epoch 7, Loss: 5.027987957000732
Epoch 8, Loss: 4.926453590393066
Epoch 9, Loss: 4.902820587158203
Epoch 10, Loss: 4.902968883514404
Epoch 11, Loss: 4.903755187988281
Epoch 12, Loss: 4.9036784172058105
Epoch 13, Loss: 4.902503967285156
Epoch 14, Loss: 4.901288986206055
Epoch 15, Loss: 4.898292541503906
Epoch 16, Loss: 4.895643711090088
Epoch 17, Loss: 4.89906120300293
Epoch 18, Loss: 4.896793842315674
Epoch 19, Loss: 4.895734786987305
Epoch 20, Loss: 4.865612030029297
Epoch 21, Loss: 4.77824592590332
Epoch 22, Loss: 4.771755218505859
Epoch 23, Loss: 4.773211479187012
Epoch 24, Loss: 4.6528096199035645
Epoch 25, Loss: 4.651209831237793
Epoch 26, Loss: 4.6521453857421875
Epoch 27, Loss: 4.646696090698242
Epoch 28, Loss: 4.651045322418213
Epoch 29, Loss: 4.651390552520752
Epoch 30, Loss: 4.777475833892822
 ~ Training finished ~
 Score: V accuracy:0.5788988003691172; J accuracy: 1.0
Iteration 38 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 256, 128], lr: 0.0001, n_drop: 0.2, use j: False ~
Epoch 1, Loss: 4.795919418334961
Epoch 2, Loss: 4.77426290512085
Epoch 3, Loss: 4.775094509124756
Epoch 4, Loss: 4.6734938621521
Epoch 5, Loss: 4.654420852661133
Epoch 6, Loss: 4.680347442626953
Epoch 7, Loss: 4.654078960418701
Epoch 8, Loss: 4.650493144989014
Epoch 9, Loss: 4.648629188537598
Epoch 10, Loss: 4.5268731117248535
Epoch 11, Loss: 4.528226375579834
Epoch 12, Loss: 4.527895927429199
Epoch 13, Loss: 4.526780128479004
Epoch 14, Loss: 4.52576208114624
Epoch 15, Loss: 4.525354385375977
Epoch 16, Loss: 4.529566287994385
Epoch 17, Loss: 4.525087833404541
Epoch 18, Loss: 4.526920795440674
Epoch 19, Loss: 4.528779983520508
Epoch 20, Loss: 4.455630302429199
Epoch 21, Loss: 4.404574394226074
Epoch 22, Loss: 4.404427528381348
Epoch 23, Loss: 4.405261039733887
Epoch 24, Loss: 4.404681205749512
Epoch 25, Loss: 4.402439117431641
Epoch 26, Loss: 4.402224540710449
Epoch 27, Loss: 4.406903266906738
Epoch 28, Loss: 4.401726722717285
Epoch 29, Loss: 4.401827812194824
Epoch 30, Loss: 4.402826309204102
 ~ Training finished ~
 Score: V accuracy:0.6413411258074438; J accuracy: 1.0
Iteration 39 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 256, 128], lr: 0.0001, n_drop: 0.3, use j: True ~
Epoch 1, Loss: 5.228137493133545
Epoch 2, Loss: 5.152528762817383
Epoch 3, Loss: 5.042982578277588
Epoch 4, Loss: 5.034945487976074
Epoch 5, Loss: 5.027276515960693
Epoch 6, Loss: 5.024242877960205
Epoch 7, Loss: 5.02527379989624
Epoch 8, Loss: 5.020174503326416
Epoch 9, Loss: 5.022732734680176
Epoch 10, Loss: 5.025556564331055
Epoch 11, Loss: 5.021120071411133
Epoch 12, Loss: 4.900487899780273
Epoch 13, Loss: 4.835695743560791
Epoch 14, Loss: 4.777017116546631
Epoch 15, Loss: 4.779542446136475
Epoch 16, Loss: 4.77755069732666
Epoch 17, Loss: 4.7785139083862305
Epoch 18, Loss: 4.7801513671875
Epoch 19, Loss: 4.776955604553223
Epoch 20, Loss: 4.777649402618408
Epoch 21, Loss: 4.804728984832764
Epoch 22, Loss: 4.774601936340332
Epoch 23, Loss: 4.784519672393799
Epoch 24, Loss: 4.7773942947387695
Epoch 25, Loss: 4.776020526885986
Epoch 26, Loss: 4.775607109069824
Epoch 27, Loss: 4.774508476257324
Epoch 28, Loss: 4.653618335723877
Epoch 29, Loss: 4.652729034423828
Epoch 30, Loss: 4.653322219848633
 ~ Training finished ~
 Score: V accuracy:0.5392187019378653; J accuracy: 1.0
Iteration 40 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 256, 128], lr: 0.0001, n_drop: 0.3, use j: False ~
Epoch 1, Loss: 5.169604301452637
Epoch 2, Loss: 5.133606433868408
Epoch 3, Loss: 5.036839485168457
Epoch 4, Loss: 5.029470920562744
Epoch 5, Loss: 5.034156322479248
Epoch 6, Loss: 5.021756172180176
Epoch 7, Loss: 5.024265289306641
Epoch 8, Loss: 5.02730655670166
Epoch 9, Loss: 5.020176887512207
Epoch 10, Loss: 4.9034271240234375
Epoch 11, Loss: 4.905666351318359
Epoch 12, Loss: 4.901988506317139
Epoch 13, Loss: 4.902388572692871
Epoch 14, Loss: 4.903880596160889
Epoch 15, Loss: 4.901017189025879
Epoch 16, Loss: 4.899919509887695
Epoch 17, Loss: 4.901173114776611
Epoch 18, Loss: 4.652653217315674
Epoch 19, Loss: 4.654752254486084
Epoch 20, Loss: 4.654638290405273
Epoch 21, Loss: 4.530340194702148
Epoch 22, Loss: 4.527964115142822
Epoch 23, Loss: 4.527632713317871
Epoch 24, Loss: 4.528030872344971
Epoch 25, Loss: 4.528370380401611
Epoch 26, Loss: 4.525911808013916
Epoch 27, Loss: 4.529181957244873
Epoch 28, Loss: 4.527642250061035
Epoch 29, Loss: 4.526082992553711
Epoch 30, Loss: 4.530446529388428
 ~ Training finished ~
 Score: V accuracy:0.5878191325745924; J accuracy: 1.0
Iteration 41 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 256, 128], lr: 0.0001, n_drop: 0.4, use j: True ~
Epoch 1, Loss: 5.1475443840026855
Epoch 2, Loss: 4.904947757720947
Epoch 3, Loss: 4.910150527954102
Epoch 4, Loss: 4.897071838378906
Epoch 5, Loss: 4.873778820037842
Epoch 6, Loss: 4.802947044372559
Epoch 7, Loss: 4.77858829498291
Epoch 8, Loss: 4.7843241691589355
Epoch 9, Loss: 4.661952018737793
Epoch 10, Loss: 4.654481410980225
Epoch 11, Loss: 4.653411865234375
Epoch 12, Loss: 4.65281867980957
Epoch 13, Loss: 4.662932872772217
Epoch 14, Loss: 4.652106285095215
Epoch 15, Loss: 4.6617512702941895
Epoch 16, Loss: 4.650880336761475
Epoch 17, Loss: 4.658263206481934
Epoch 18, Loss: 4.6570539474487305
Epoch 19, Loss: 4.654747009277344
Epoch 20, Loss: 4.653864860534668
Epoch 21, Loss: 4.654506683349609
Epoch 22, Loss: 4.655306816101074
Epoch 23, Loss: 4.652389049530029
Epoch 24, Loss: 4.655323028564453
Epoch 25, Loss: 4.65242338180542
Epoch 26, Loss: 4.652116775512695
Epoch 27, Loss: 4.65336799621582
Epoch 28, Loss: 4.654101371765137
Epoch 29, Loss: 4.649969100952148
Epoch 30, Loss: 4.6509623527526855
 ~ Training finished ~
 Score: V accuracy:0.5518302060904338; J accuracy: 1.0
Iteration 42 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 256, 128], lr: 0.0001, n_drop: 0.4, use j: False ~
Epoch 1, Loss: 5.019400596618652
Epoch 2, Loss: 4.861017227172852
Epoch 3, Loss: 4.784932613372803
Epoch 4, Loss: 4.775684833526611
Epoch 5, Loss: 4.7733154296875
Epoch 6, Loss: 4.77437162399292
Epoch 7, Loss: 4.77628231048584
Epoch 8, Loss: 4.7797346115112305
Epoch 9, Loss: 4.776984214782715
Epoch 10, Loss: 4.652887344360352
Epoch 11, Loss: 4.655176639556885
Epoch 12, Loss: 4.652431488037109
Epoch 13, Loss: 4.655345439910889
Epoch 14, Loss: 4.656038284301758
Epoch 15, Loss: 4.651500225067139
Epoch 16, Loss: 4.655625343322754
Epoch 17, Loss: 4.78721284866333
Epoch 18, Loss: 4.7018723487854
Epoch 19, Loss: 4.654106616973877
Epoch 20, Loss: 4.660043239593506
Epoch 21, Loss: 4.652988910675049
Epoch 22, Loss: 4.654038429260254
Epoch 23, Loss: 4.652558326721191
Epoch 24, Loss: 4.656554222106934
Epoch 25, Loss: 4.653719425201416
Epoch 26, Loss: 4.649937629699707
Epoch 27, Loss: 4.6371941566467285
Epoch 28, Loss: 4.554919242858887
Epoch 29, Loss: 4.599245548248291
Epoch 30, Loss: 4.530280590057373
 ~ Training finished ~
 Score: V accuracy:0.48569670870501386; J accuracy: 1.0
Iteration 43 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 256, 128], lr: 1e-05, n_drop: 0.2, use j: True ~
Epoch 1, Loss: 5.109586715698242
Epoch 2, Loss: 5.031802177429199
Epoch 3, Loss: 5.018181800842285
Epoch 4, Loss: 5.023212909698486
Epoch 5, Loss: 5.018585681915283
Epoch 6, Loss: 4.988405227661133
Epoch 7, Loss: 4.778196811676025
Epoch 8, Loss: 4.678526401519775
Epoch 9, Loss: 4.744855880737305
Epoch 10, Loss: 4.737482070922852
Epoch 11, Loss: 4.6620564460754395
Epoch 12, Loss: 4.658536911010742
Epoch 13, Loss: 4.661880016326904
Epoch 14, Loss: 4.659506797790527
Epoch 15, Loss: 4.661134719848633
Epoch 16, Loss: 4.682257652282715
Epoch 17, Loss: 4.664272785186768
Epoch 18, Loss: 4.661315441131592
Epoch 19, Loss: 4.6571855545043945
Epoch 20, Loss: 4.6564435958862305
Epoch 21, Loss: 4.655713081359863
Epoch 22, Loss: 4.664567470550537
Epoch 23, Loss: 4.653332710266113
Epoch 24, Loss: 4.656606197357178
Epoch 25, Loss: 4.653584003448486
Epoch 26, Loss: 4.652605056762695
Epoch 27, Loss: 4.656375885009766
Epoch 28, Loss: 4.652200698852539
Epoch 29, Loss: 4.650920391082764
Epoch 30, Loss: 4.650615692138672
 ~ Training finished ~
 Score: V accuracy:0.5216856351891725; J accuracy: 1.0
Iteration 44 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 256, 128], lr: 1e-05, n_drop: 0.2, use j: False ~
Epoch 1, Loss: 5.241152286529541
Epoch 2, Loss: 5.0259318351745605
Epoch 3, Loss: 4.979949474334717
Epoch 4, Loss: 4.865760803222656
Epoch 5, Loss: 4.806440353393555
Epoch 6, Loss: 4.83293342590332
Epoch 7, Loss: 4.800474166870117
Epoch 8, Loss: 4.791205406188965
Epoch 9, Loss: 4.781098365783691
Epoch 10, Loss: 4.779760837554932
Epoch 11, Loss: 4.714665412902832
Epoch 12, Loss: 4.70758581161499
Epoch 13, Loss: 4.65537691116333
Epoch 14, Loss: 4.656050205230713
Epoch 15, Loss: 4.650149345397949
Epoch 16, Loss: 4.535907745361328
Epoch 17, Loss: 4.541398048400879
Epoch 18, Loss: 4.529784202575684
Epoch 19, Loss: 4.533641815185547
Epoch 20, Loss: 4.533358097076416
Epoch 21, Loss: 4.532843112945557
Epoch 22, Loss: 4.5292558670043945
Epoch 23, Loss: 4.5304765701293945
Epoch 24, Loss: 4.53450345993042
Epoch 25, Loss: 4.529404163360596
Epoch 26, Loss: 4.527559280395508
Epoch 27, Loss: 4.5280022621154785
Epoch 28, Loss: 4.543581962585449
Epoch 29, Loss: 4.528153896331787
Epoch 30, Loss: 4.528200626373291
 ~ Training finished ~
 Score: V accuracy:0.5056905567517687; J accuracy: 1.0
Iteration 45 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 256, 128], lr: 1e-05, n_drop: 0.3, use j: True ~
Epoch 1, Loss: 5.363238334655762
Epoch 2, Loss: 5.244728088378906
Epoch 3, Loss: 5.181840419769287
Epoch 4, Loss: 5.025712966918945
Epoch 5, Loss: 5.012375831604004
Epoch 6, Loss: 4.846112251281738
Epoch 7, Loss: 4.7908124923706055
Epoch 8, Loss: 4.877460479736328
Epoch 9, Loss: 4.803594589233398
Epoch 10, Loss: 4.8211565017700195
Epoch 11, Loss: 4.7834601402282715
Epoch 12, Loss: 4.776483058929443
Epoch 13, Loss: 4.787370681762695
Epoch 14, Loss: 4.7869157791137695
Epoch 15, Loss: 4.777188777923584
Epoch 16, Loss: 4.757153034210205
Epoch 17, Loss: 4.772714614868164
Epoch 18, Loss: 4.747467041015625
Epoch 19, Loss: 4.689803123474121
Epoch 20, Loss: 4.653039932250977
Epoch 21, Loss: 4.712003231048584
Epoch 22, Loss: 4.691511154174805
Epoch 23, Loss: 4.652220726013184
Epoch 24, Loss: 4.649509429931641
Epoch 25, Loss: 4.655109882354736
Epoch 26, Loss: 4.663424015045166
Epoch 27, Loss: 4.65828800201416
Epoch 28, Loss: 4.6536431312561035
Epoch 29, Loss: 4.65121603012085
Epoch 30, Loss: 4.652593612670898
 ~ Training finished ~
 Score: V accuracy:0.5358351276530299; J accuracy: 1.0
Iteration 46 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 256, 128], lr: 1e-05, n_drop: 0.3, use j: False ~
Epoch 1, Loss: 5.375392913818359
Epoch 2, Loss: 5.292362689971924
Epoch 3, Loss: 5.189767837524414
Epoch 4, Loss: 5.155360221862793
Epoch 5, Loss: 5.179627895355225
Epoch 6, Loss: 5.150705814361572
Epoch 7, Loss: 5.140384197235107
Epoch 8, Loss: 5.019193172454834
Epoch 9, Loss: 5.023678779602051
Epoch 10, Loss: 4.90895414352417
Epoch 11, Loss: 4.911181449890137
Epoch 12, Loss: 4.914632797241211
Epoch 13, Loss: 4.918910503387451
Epoch 14, Loss: 4.994960784912109
Epoch 15, Loss: 4.934121131896973
Epoch 16, Loss: 4.912274360656738
Epoch 17, Loss: 4.918673515319824
Epoch 18, Loss: 4.915125846862793
Epoch 19, Loss: 4.906400680541992
Epoch 20, Loss: 4.9039740562438965
Epoch 21, Loss: 4.937135219573975
Epoch 22, Loss: 4.927779674530029
Epoch 23, Loss: 4.912457466125488
Epoch 24, Loss: 4.908317565917969
Epoch 25, Loss: 4.905076503753662
Epoch 26, Loss: 4.9026265144348145
Epoch 27, Loss: 4.9027099609375
Epoch 28, Loss: 4.902350425720215
Epoch 29, Loss: 4.904675483703613
Epoch 30, Loss: 4.902750492095947
 ~ Training finished ~
 Score: V accuracy:0.47247000922792987; J accuracy: 1.0
Iteration 47 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 256, 128], lr: 1e-05, n_drop: 0.4, use j: True ~
Epoch 1, Loss: 5.484068393707275
Epoch 2, Loss: 5.3407673835754395
Epoch 3, Loss: 5.2808027267456055
Epoch 4, Loss: 5.223028182983398
Epoch 5, Loss: 5.080844402313232
Epoch 6, Loss: 5.040618896484375
Epoch 7, Loss: 5.1191511154174805
Epoch 8, Loss: 5.120148658752441
Epoch 9, Loss: 5.0303168296813965
Epoch 10, Loss: 5.127323150634766
Epoch 11, Loss: 5.139204025268555
Epoch 12, Loss: 5.036516189575195
Epoch 13, Loss: 4.9447221755981445
Epoch 14, Loss: 4.9956207275390625
Epoch 15, Loss: 4.916253566741943
Epoch 16, Loss: 4.9107770919799805
Epoch 17, Loss: 4.90350341796875
Epoch 18, Loss: 4.909543037414551
Epoch 19, Loss: 4.903524398803711
Epoch 20, Loss: 4.923317909240723
Epoch 21, Loss: 4.917364120483398
Epoch 22, Loss: 4.9029459953308105
Epoch 23, Loss: 4.90000057220459
Epoch 24, Loss: 4.942782878875732
Epoch 25, Loss: 4.907691955566406
Epoch 26, Loss: 4.903059005737305
Epoch 27, Loss: 4.900518894195557
Epoch 28, Loss: 4.957003116607666
Epoch 29, Loss: 4.994553565979004
Epoch 30, Loss: 4.896800518035889
 ~ Training finished ~
 Score: V accuracy:0.43924946170409107; J accuracy: 1.0
Iteration 48 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 256, 128], lr: 1e-05, n_drop: 0.4, use j: False ~
Epoch 1, Loss: 5.299137592315674
Epoch 2, Loss: 5.105199337005615
Epoch 3, Loss: 5.065237045288086
Epoch 4, Loss: 5.025269985198975
Epoch 5, Loss: 5.0087666511535645
Epoch 6, Loss: 4.901483535766602
Epoch 7, Loss: 4.904903411865234
Epoch 8, Loss: 4.900424957275391
Epoch 9, Loss: 4.902804374694824
Epoch 10, Loss: 4.791539669036865
Epoch 11, Loss: 4.793440818786621
Epoch 12, Loss: 4.782034873962402
Epoch 13, Loss: 4.773605823516846
Epoch 14, Loss: 4.773874282836914
Epoch 15, Loss: 4.776241302490234
Epoch 16, Loss: 4.783145904541016
Epoch 17, Loss: 4.711581230163574
Epoch 18, Loss: 4.668227195739746
Epoch 19, Loss: 4.77266263961792
Epoch 20, Loss: 4.768732070922852
Epoch 21, Loss: 4.750425815582275
Epoch 22, Loss: 4.736382007598877
Epoch 23, Loss: 4.724266529083252
Epoch 24, Loss: 4.6595869064331055
Epoch 25, Loss: 4.57888650894165
Epoch 26, Loss: 4.545462608337402
Epoch 27, Loss: 4.593598365783691
Epoch 28, Loss: 4.55091667175293
Epoch 29, Loss: 4.582376480102539
Epoch 30, Loss: 4.596381187438965
 ~ Training finished ~
 Score: V accuracy:0.49400184558597354; J accuracy: 0.9704706244232544
Iteration 49 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 320, 180], lr: 0.0001, n_drop: 0.2, use j: True ~
Epoch 1, Loss: 5.034599304199219
Epoch 2, Loss: 4.921441555023193
Epoch 3, Loss: 4.786476135253906
Epoch 4, Loss: 4.78123664855957
Epoch 5, Loss: 4.780097007751465
Epoch 6, Loss: 4.7805585861206055
Epoch 7, Loss: 4.777700901031494
Epoch 8, Loss: 4.779387474060059
Epoch 9, Loss: 4.776381015777588
Epoch 10, Loss: 4.776402950286865
Epoch 11, Loss: 4.774347305297852
Epoch 12, Loss: 4.776756286621094
Epoch 13, Loss: 4.793071746826172
Epoch 14, Loss: 4.775525093078613
Epoch 15, Loss: 4.775045871734619
Epoch 16, Loss: 4.781022548675537
Epoch 17, Loss: 4.790813446044922
Epoch 18, Loss: 4.773830413818359
Epoch 19, Loss: 4.77303409576416
Epoch 20, Loss: 4.542342185974121
Epoch 21, Loss: 4.527780532836914
Epoch 22, Loss: 4.5276618003845215
Epoch 23, Loss: 4.527323246002197
Epoch 24, Loss: 4.528721332550049
Epoch 25, Loss: 4.52712869644165
Epoch 26, Loss: 4.405396938323975
Epoch 27, Loss: 4.404576301574707
Epoch 28, Loss: 4.404884338378906
Epoch 29, Loss: 4.405224323272705
Epoch 30, Loss: 4.405019283294678
 ~ Training finished ~
 Score: V accuracy:0.6241156567210089; J accuracy: 1.0
Iteration 50 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 320, 180], lr: 0.0001, n_drop: 0.2, use j: False ~
Epoch 1, Loss: 4.7858567237854
Epoch 2, Loss: 4.678424835205078
Epoch 3, Loss: 4.532848358154297
Epoch 4, Loss: 4.529196739196777
Epoch 5, Loss: 4.530529975891113
Epoch 6, Loss: 4.528224945068359
Epoch 7, Loss: 4.527512550354004
Epoch 8, Loss: 4.533373832702637
Epoch 9, Loss: 4.531827926635742
Epoch 10, Loss: 4.530434608459473
Epoch 11, Loss: 4.530803203582764
Epoch 12, Loss: 4.528012275695801
Epoch 13, Loss: 4.527604103088379
Epoch 14, Loss: 4.527408599853516
Epoch 15, Loss: 4.526495933532715
Epoch 16, Loss: 4.4282331466674805
Epoch 17, Loss: 4.279109001159668
Epoch 18, Loss: 4.2793779373168945
Epoch 19, Loss: 4.279376029968262
Epoch 20, Loss: 4.279604911804199
Epoch 21, Loss: 4.407340049743652
Epoch 22, Loss: 4.281230449676514
Epoch 23, Loss: 4.278181552886963
Epoch 24, Loss: 4.278841018676758
Epoch 25, Loss: 4.27823543548584
Epoch 26, Loss: 4.278463363647461
Epoch 27, Loss: 4.2804436683654785
Epoch 28, Loss: 4.279355049133301
Epoch 29, Loss: 4.279698371887207
Epoch 30, Loss: 4.278313636779785
 ~ Training finished ~
 Score: V accuracy:0.6333435865887419; J accuracy: 1.0
Iteration 51 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 320, 180], lr: 0.0001, n_drop: 0.3, use j: True ~
Epoch 1, Loss: 5.069494247436523
Epoch 2, Loss: 4.717167377471924
Epoch 3, Loss: 4.657533645629883
Epoch 4, Loss: 4.6927056312561035
Epoch 5, Loss: 4.668341636657715
Epoch 6, Loss: 4.652838706970215
Epoch 7, Loss: 4.652379989624023
Epoch 8, Loss: 4.522274017333984
Epoch 9, Loss: 4.405803203582764
Epoch 10, Loss: 4.598504066467285
Epoch 11, Loss: 4.404377460479736
Epoch 12, Loss: 4.405972957611084
Epoch 13, Loss: 4.405978679656982
Epoch 14, Loss: 4.406917572021484
Epoch 15, Loss: 4.4049763679504395
Epoch 16, Loss: 4.406311988830566
Epoch 17, Loss: 4.405087471008301
Epoch 18, Loss: 4.405935287475586
Epoch 19, Loss: 4.406054973602295
Epoch 20, Loss: 4.4046149253845215
Epoch 21, Loss: 4.406003475189209
Epoch 22, Loss: 4.406388282775879
Epoch 23, Loss: 4.405900001525879
Epoch 24, Loss: 4.4052815437316895
Epoch 25, Loss: 4.405874252319336
Epoch 26, Loss: 4.414872169494629
Epoch 27, Loss: 4.405943393707275
Epoch 28, Loss: 4.406030654907227
Epoch 29, Loss: 4.404903411865234
Epoch 30, Loss: 4.405529022216797
 ~ Training finished ~
 Score: V accuracy:0.5862811442633036; J accuracy: 1.0
Iteration 52 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 320, 180], lr: 0.0001, n_drop: 0.3, use j: False ~
Epoch 1, Loss: 5.208317756652832
Epoch 2, Loss: 5.148395538330078
Epoch 3, Loss: 5.148305892944336
Epoch 4, Loss: 5.144803524017334
Epoch 5, Loss: 5.14518928527832
Epoch 6, Loss: 5.148537635803223
Epoch 7, Loss: 5.026951313018799
Epoch 8, Loss: 5.028678894042969
Epoch 9, Loss: 5.0269060134887695
Epoch 10, Loss: 5.026771068572998
Epoch 11, Loss: 4.904057502746582
Epoch 12, Loss: 4.905642509460449
Epoch 13, Loss: 4.781589508056641
Epoch 14, Loss: 4.778393745422363
Epoch 15, Loss: 4.778131484985352
Epoch 16, Loss: 4.7776384353637695
Epoch 17, Loss: 4.7803215980529785
Epoch 18, Loss: 4.780516624450684
Epoch 19, Loss: 4.775301933288574
Epoch 20, Loss: 4.772137641906738
Epoch 21, Loss: 4.773848533630371
Epoch 22, Loss: 4.772290229797363
Epoch 23, Loss: 4.773318767547607
Epoch 24, Loss: 4.528045654296875
Epoch 25, Loss: 4.5298967361450195
Epoch 26, Loss: 4.5285820960998535
Epoch 27, Loss: 4.528863430023193
Epoch 28, Loss: 4.526176929473877
Epoch 29, Loss: 4.527712821960449
Epoch 30, Loss: 4.530520439147949
 ~ Training finished ~
 Score: V accuracy:0.5481390341433405; J accuracy: 1.0
Iteration 53 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 320, 180], lr: 0.0001, n_drop: 0.4, use j: True ~
Epoch 1, Loss: 5.151620864868164
Epoch 2, Loss: 5.125762939453125
Epoch 3, Loss: 5.14300537109375
Epoch 4, Loss: 5.025592803955078
Epoch 5, Loss: 5.032725811004639
Epoch 6, Loss: 5.077741622924805
Epoch 7, Loss: 4.901864051818848
Epoch 8, Loss: 4.901926040649414
Epoch 9, Loss: 4.900627136230469
Epoch 10, Loss: 4.902003288269043
Epoch 11, Loss: 4.90303897857666
Epoch 12, Loss: 4.911633491516113
Epoch 13, Loss: 4.899040222167969
Epoch 14, Loss: 4.899633884429932
Epoch 15, Loss: 4.654260635375977
Epoch 16, Loss: 4.530050277709961
Epoch 17, Loss: 4.463361740112305
Epoch 18, Loss: 4.403585433959961
Epoch 19, Loss: 4.406064510345459
Epoch 20, Loss: 4.406241416931152
Epoch 21, Loss: 4.4071044921875
Epoch 22, Loss: 4.40566349029541
Epoch 23, Loss: 4.519798755645752
Epoch 24, Loss: 4.404207706451416
Epoch 25, Loss: 4.403141975402832
Epoch 26, Loss: 4.408257484436035
Epoch 27, Loss: 4.404425144195557
Epoch 28, Loss: 4.4058613777160645
Epoch 29, Loss: 4.405605792999268
Epoch 30, Loss: 4.402665138244629
 ~ Training finished ~
 Score: V accuracy:0.5764380190710551; J accuracy: 1.0
Iteration 54 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 320, 180], lr: 0.0001, n_drop: 0.4, use j: False ~
Epoch 1, Loss: 5.215125560760498
Epoch 2, Loss: 5.147981643676758
Epoch 3, Loss: 5.040549278259277
Epoch 4, Loss: 5.048788070678711
Epoch 5, Loss: 5.026796817779541
Epoch 6, Loss: 5.023180961608887
Epoch 7, Loss: 5.019656181335449
Epoch 8, Loss: 5.021674156188965
Epoch 9, Loss: 5.0238142013549805
Epoch 10, Loss: 4.904006004333496
Epoch 11, Loss: 4.904232501983643
Epoch 12, Loss: 4.900582313537598
Epoch 13, Loss: 4.903472900390625
Epoch 14, Loss: 4.901664733886719
Epoch 15, Loss: 4.9037909507751465
Epoch 16, Loss: 4.904361724853516
Epoch 17, Loss: 4.902358531951904
Epoch 18, Loss: 4.902106285095215
Epoch 19, Loss: 4.9012322425842285
Epoch 20, Loss: 4.782083988189697
Epoch 21, Loss: 4.7773942947387695
Epoch 22, Loss: 4.780066013336182
Epoch 23, Loss: 4.7784013748168945
Epoch 24, Loss: 4.77961540222168
Epoch 25, Loss: 4.816597938537598
Epoch 26, Loss: 4.777311325073242
Epoch 27, Loss: 4.773787498474121
Epoch 28, Loss: 4.778216361999512
Epoch 29, Loss: 4.775837421417236
Epoch 30, Loss: 4.776031970977783
 ~ Training finished ~
 Score: V accuracy:0.5444478621962473; J accuracy: 1.0
Iteration 55 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 320, 180], lr: 1e-05, n_drop: 0.2, use j: True ~
Epoch 1, Loss: 5.162583827972412
Epoch 2, Loss: 5.033681392669678
Epoch 3, Loss: 5.020387649536133
Epoch 4, Loss: 5.021251678466797
Epoch 5, Loss: 5.0538649559021
Epoch 6, Loss: 5.018838882446289
Epoch 7, Loss: 4.907257556915283
Epoch 8, Loss: 4.813401222229004
Epoch 9, Loss: 4.885448455810547
Epoch 10, Loss: 4.782995700836182
Epoch 11, Loss: 4.661129951477051
Epoch 12, Loss: 4.663018226623535
Epoch 13, Loss: 4.658331871032715
Epoch 14, Loss: 4.662410259246826
Epoch 15, Loss: 4.659523963928223
Epoch 16, Loss: 4.659040451049805
Epoch 17, Loss: 4.656012535095215
Epoch 18, Loss: 4.655634880065918
Epoch 19, Loss: 4.655374050140381
Epoch 20, Loss: 4.657596588134766
Epoch 21, Loss: 4.6539201736450195
Epoch 22, Loss: 4.655230522155762
Epoch 23, Loss: 4.653535842895508
Epoch 24, Loss: 4.650405406951904
Epoch 25, Loss: 4.650908946990967
Epoch 26, Loss: 4.5318217277526855
Epoch 27, Loss: 4.533556938171387
Epoch 28, Loss: 4.518784523010254
Epoch 29, Loss: 4.428719520568848
Epoch 30, Loss: 4.414154052734375
 ~ Training finished ~
 Score: V accuracy:0.5053829590895109; J accuracy: 1.0
Iteration 56 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 320, 180], lr: 1e-05, n_drop: 0.2, use j: False ~
Epoch 1, Loss: 5.392786026000977
Epoch 2, Loss: 5.246208667755127
Epoch 3, Loss: 5.172586441040039
Epoch 4, Loss: 5.037116527557373
Epoch 5, Loss: 5.0307722091674805
Epoch 6, Loss: 5.026472091674805
Epoch 7, Loss: 5.030233383178711
Epoch 8, Loss: 5.030921936035156
Epoch 9, Loss: 5.028522491455078
Epoch 10, Loss: 5.028087139129639
Epoch 11, Loss: 4.931335926055908
Epoch 12, Loss: 4.9147467613220215
Epoch 13, Loss: 4.907516956329346
Epoch 14, Loss: 4.905912399291992
Epoch 15, Loss: 4.907883167266846
Epoch 16, Loss: 4.9208245277404785
Epoch 17, Loss: 4.902897357940674
Epoch 18, Loss: 4.904529571533203
Epoch 19, Loss: 4.904675483703613
Epoch 20, Loss: 4.9081501960754395
Epoch 21, Loss: 4.904439926147461
Epoch 22, Loss: 4.902320861816406
Epoch 23, Loss: 4.903153419494629
Epoch 24, Loss: 4.902369499206543
Epoch 25, Loss: 4.9019975662231445
Epoch 26, Loss: 4.901276588439941
Epoch 27, Loss: 4.902967929840088
Epoch 28, Loss: 4.903038501739502
Epoch 29, Loss: 4.905056476593018
Epoch 30, Loss: 4.903245449066162
 ~ Training finished ~
 Score: V accuracy:0.410335281451861; J accuracy: 1.0
Iteration 57 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 320, 180], lr: 1e-05, n_drop: 0.3, use j: True ~
Epoch 1, Loss: 5.393492221832275
Epoch 2, Loss: 5.387652397155762
Epoch 3, Loss: 5.358732223510742
Epoch 4, Loss: 5.265488624572754
Epoch 5, Loss: 5.258519172668457
Epoch 6, Loss: 5.238649368286133
Epoch 7, Loss: 5.0368146896362305
Epoch 8, Loss: 5.075449466705322
Epoch 9, Loss: 5.025299072265625
Epoch 10, Loss: 5.021134853363037
Epoch 11, Loss: 4.919923305511475
Epoch 12, Loss: 4.816866397857666
Epoch 13, Loss: 4.817868709564209
Epoch 14, Loss: 4.853601455688477
Epoch 15, Loss: 4.8104963302612305
Epoch 16, Loss: 4.787647724151611
Epoch 17, Loss: 4.784307479858398
Epoch 18, Loss: 4.787567615509033
Epoch 19, Loss: 4.781000137329102
Epoch 20, Loss: 4.815702438354492
Epoch 21, Loss: 4.779765605926514
Epoch 22, Loss: 4.779844760894775
Epoch 23, Loss: 4.780543327331543
Epoch 24, Loss: 4.778622627258301
Epoch 25, Loss: 4.778964519500732
Epoch 26, Loss: 4.777983665466309
Epoch 27, Loss: 4.777409076690674
Epoch 28, Loss: 4.77742862701416
Epoch 29, Loss: 4.776981830596924
Epoch 30, Loss: 4.7772216796875
 ~ Training finished ~
 Score: V accuracy:0.39464780067671484; J accuracy: 1.0
Iteration 58 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 320, 180], lr: 1e-05, n_drop: 0.3, use j: False ~
Epoch 1, Loss: 5.415266036987305
Epoch 2, Loss: 5.286291122436523
Epoch 3, Loss: 5.161571979522705
Epoch 4, Loss: 5.151973247528076
Epoch 5, Loss: 5.150626182556152
Epoch 6, Loss: 5.154654502868652
Epoch 7, Loss: 5.150063514709473
Epoch 8, Loss: 5.1477885246276855
Epoch 9, Loss: 5.151673316955566
Epoch 10, Loss: 5.064483642578125
Epoch 11, Loss: 5.050468444824219
Epoch 12, Loss: 5.028285980224609
Epoch 13, Loss: 5.03028678894043
Epoch 14, Loss: 5.030777931213379
Epoch 15, Loss: 4.937138557434082
Epoch 16, Loss: 4.98218297958374
Epoch 17, Loss: 4.916927814483643
Epoch 18, Loss: 4.904438495635986
Epoch 19, Loss: 4.9051055908203125
Epoch 20, Loss: 4.917396545410156
Epoch 21, Loss: 4.917590141296387
Epoch 22, Loss: 4.910178184509277
Epoch 23, Loss: 4.90057373046875
Epoch 24, Loss: 4.901907920837402
Epoch 25, Loss: 4.902164936065674
Epoch 26, Loss: 4.900931358337402
Epoch 27, Loss: 4.902338027954102
Epoch 28, Loss: 4.897822380065918
Epoch 29, Loss: 4.901167869567871
Epoch 30, Loss: 4.902437686920166
 ~ Training finished ~
 Score: V accuracy:0.4201784066441095; J accuracy: 1.0
Iteration 59 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 320, 180], lr: 1e-05, n_drop: 0.4, use j: True ~
Epoch 1, Loss: 5.441065788269043
Epoch 2, Loss: 5.396308898925781
Epoch 3, Loss: 5.389688491821289
Epoch 4, Loss: 5.339484691619873
Epoch 5, Loss: 5.155500888824463
Epoch 6, Loss: 5.147852420806885
Epoch 7, Loss: 5.173643112182617
Epoch 8, Loss: 5.154502868652344
Epoch 9, Loss: 5.160072326660156
Epoch 10, Loss: 5.15205192565918
Epoch 11, Loss: 5.150041580200195
Epoch 12, Loss: 5.030979633331299
Epoch 13, Loss: 5.027878761291504
Epoch 14, Loss: 5.0289692878723145
Epoch 15, Loss: 5.028816223144531
Epoch 16, Loss: 4.958271026611328
Epoch 17, Loss: 4.9672417640686035
Epoch 18, Loss: 4.902222156524658
Epoch 19, Loss: 4.94326114654541
Epoch 20, Loss: 4.904617786407471
Epoch 21, Loss: 4.901456832885742
Epoch 22, Loss: 4.904531955718994
Epoch 23, Loss: 4.897177696228027
Epoch 24, Loss: 4.869947910308838
Epoch 25, Loss: 4.697645664215088
Epoch 26, Loss: 4.7636799812316895
Epoch 27, Loss: 4.687331676483154
Epoch 28, Loss: 4.704371929168701
Epoch 29, Loss: 4.653913974761963
Epoch 30, Loss: 4.687209606170654
 ~ Training finished ~
 Score: V accuracy:0.40972008612734545; J accuracy: 1.0
Iteration 60 of 72
   ~ Training for parameters: Hid_layer_size: [1024, 512, 320, 180], lr: 1e-05, n_drop: 0.4, use j: False ~
Epoch 1, Loss: 5.396856307983398
Epoch 2, Loss: 5.329754829406738
Epoch 3, Loss: 5.278100967407227
Epoch 4, Loss: 5.271818161010742
Epoch 5, Loss: 5.263937950134277
Epoch 6, Loss: 5.260107040405273
Epoch 7, Loss: 5.254294395446777
Epoch 8, Loss: 5.223060607910156
Epoch 9, Loss: 5.163389682769775
Epoch 10, Loss: 5.19477653503418
Epoch 11, Loss: 5.0370192527771
Epoch 12, Loss: 5.027220249176025
Epoch 13, Loss: 5.033461570739746
Epoch 14, Loss: 5.012613296508789
Epoch 15, Loss: 5.041220664978027
Epoch 16, Loss: 5.108747959136963
Epoch 17, Loss: 5.031322002410889
Epoch 18, Loss: 4.920457363128662
Epoch 19, Loss: 4.900373458862305
Epoch 20, Loss: 4.904976844787598
Epoch 21, Loss: 4.9113545417785645
Epoch 22, Loss: 4.900474548339844
Epoch 23, Loss: 4.9036359786987305
Epoch 24, Loss: 4.893743991851807
Epoch 25, Loss: 4.803138732910156
Epoch 26, Loss: 4.92033052444458
Epoch 27, Loss: 4.82354736328125
Epoch 28, Loss: 4.780399322509766
Epoch 29, Loss: 4.55452823638916
Epoch 30, Loss: 4.583780288696289
 ~ Training finished ~
 Score: V accuracy:0.5819747769916949; J accuracy: 0.9535527529990772
Iteration 61 of 72
   ~ Training for parameters: Hid_layer_size: [1500, 1000, 750, 500, 200], lr: 0.0001, n_drop: 0.2, use j: True ~
Epoch 1, Loss: 5.0214056968688965
Epoch 2, Loss: 4.90024471282959
Epoch 3, Loss: 4.776775360107422
Epoch 4, Loss: 4.7780256271362305
Epoch 5, Loss: 4.661634922027588
Epoch 6, Loss: 4.660432815551758
Epoch 7, Loss: 4.651366233825684
Epoch 8, Loss: 4.65455961227417
Epoch 9, Loss: 4.656664848327637
Epoch 10, Loss: 4.653371334075928
Epoch 11, Loss: 4.654642105102539
Epoch 12, Loss: 4.655450820922852
Epoch 13, Loss: 4.654934883117676
Epoch 14, Loss: 4.660904407501221
Epoch 15, Loss: 4.780582427978516
Epoch 16, Loss: 4.529542922973633
Epoch 17, Loss: 4.530798435211182
Epoch 18, Loss: 4.531157493591309
Epoch 19, Loss: 4.529246807098389
Epoch 20, Loss: 4.655045986175537
Epoch 21, Loss: 4.528945446014404
Epoch 22, Loss: 4.543344974517822
Epoch 23, Loss: 4.529332160949707
Epoch 24, Loss: 4.677465915679932
Epoch 25, Loss: 4.52912712097168
Epoch 26, Loss: 4.546127796173096
Epoch 27, Loss: 4.530828475952148
Epoch 28, Loss: 4.530303955078125
Epoch 29, Loss: 4.5297160148620605
Epoch 30, Loss: 4.531018257141113
 ~ Training finished ~
 Score: V accuracy:0.5204552445401415; J accuracy: 1.0
Iteration 62 of 72
   ~ Training for parameters: Hid_layer_size: [1500, 1000, 750, 500, 200], lr: 0.0001, n_drop: 0.2, use j: False ~
Epoch 1, Loss: 5.277376174926758
Epoch 2, Loss: 5.149463653564453
Epoch 3, Loss: 5.151113510131836
Epoch 4, Loss: 5.152070999145508
Epoch 5, Loss: 5.1404876708984375
Epoch 6, Loss: 4.9226179122924805
Epoch 7, Loss: 4.902193546295166
Epoch 8, Loss: 4.905318737030029
Epoch 9, Loss: 4.778779983520508
Epoch 10, Loss: 4.780849456787109
Epoch 11, Loss: 4.778266429901123
Epoch 12, Loss: 4.7776055335998535
Epoch 13, Loss: 4.775431156158447
Epoch 14, Loss: 4.786716461181641
Epoch 15, Loss: 4.778961658477783
Epoch 16, Loss: 4.659374237060547
Epoch 17, Loss: 4.563749313354492
Epoch 18, Loss: 4.530473232269287
Epoch 19, Loss: 4.542384624481201
Epoch 20, Loss: 4.530973434448242
Epoch 21, Loss: 4.529329776763916
Epoch 22, Loss: 4.531394004821777
Epoch 23, Loss: 4.544814586639404
Epoch 24, Loss: 4.530851364135742
Epoch 25, Loss: 4.530241966247559
Epoch 26, Loss: 4.611339569091797
Epoch 27, Loss: 4.530857086181641
Epoch 28, Loss: 4.531796932220459
Epoch 29, Loss: 4.5309319496154785
Epoch 30, Loss: 4.5306501388549805
 ~ Training finished ~
 Score: V accuracy:0.6078129806213473; J accuracy: 1.0
Iteration 63 of 72
   ~ Training for parameters: Hid_layer_size: [1500, 1000, 750, 500, 200], lr: 0.0001, n_drop: 0.3, use j: True ~
Epoch 1, Loss: 5.144742488861084
Epoch 2, Loss: 5.028784275054932
Epoch 3, Loss: 4.908413887023926
Epoch 4, Loss: 4.904628276824951
Epoch 5, Loss: 4.912286758422852
Epoch 6, Loss: 4.909350395202637
Epoch 7, Loss: 4.9035420417785645
Epoch 8, Loss: 4.90308952331543
Epoch 9, Loss: 4.903754711151123
Epoch 10, Loss: 4.912497520446777
Epoch 11, Loss: 4.904331207275391
Epoch 12, Loss: 4.7819390296936035
Epoch 13, Loss: 4.778365612030029
Epoch 14, Loss: 4.782904624938965
Epoch 15, Loss: 4.77928352355957
Epoch 16, Loss: 4.7802605628967285
Epoch 17, Loss: 4.880698204040527
Epoch 18, Loss: 4.789427757263184
Epoch 19, Loss: 4.658819675445557
Epoch 20, Loss: 4.652836799621582
Epoch 21, Loss: 4.655014514923096
Epoch 22, Loss: 4.657900333404541
Epoch 23, Loss: 4.654672622680664
Epoch 24, Loss: 4.653226375579834
Epoch 25, Loss: 4.653762340545654
Epoch 26, Loss: 4.657197952270508
Epoch 27, Loss: 4.655701160430908
Epoch 28, Loss: 4.780241966247559
Epoch 29, Loss: 4.658805847167969
Epoch 30, Loss: 4.655018329620361
 ~ Training finished ~
 Score: V accuracy:0.5262996001230391; J accuracy: 1.0
Iteration 64 of 72
   ~ Training for parameters: Hid_layer_size: [1500, 1000, 750, 500, 200], lr: 0.0001, n_drop: 0.3, use j: False ~
Epoch 1, Loss: 5.152349948883057
Epoch 2, Loss: 5.1507720947265625
Epoch 3, Loss: 5.148052215576172
Epoch 4, Loss: 5.1501145362854
Epoch 5, Loss: 5.153066635131836
Epoch 6, Loss: 5.115267753601074
Epoch 7, Loss: 5.024650573730469
Epoch 8, Loss: 5.046139717102051
Epoch 9, Loss: 4.7377495765686035
Epoch 10, Loss: 4.655576229095459
Epoch 11, Loss: 4.653397083282471
Epoch 12, Loss: 4.654857635498047
Epoch 13, Loss: 4.654745101928711
Epoch 14, Loss: 4.653658866882324
Epoch 15, Loss: 4.654352188110352
Epoch 16, Loss: 4.653835773468018
Epoch 17, Loss: 4.655440807342529
Epoch 18, Loss: 4.704318523406982
Epoch 19, Loss: 4.655179023742676
Epoch 20, Loss: 4.655791759490967
Epoch 21, Loss: 4.654900550842285
Epoch 22, Loss: 4.654858589172363
Epoch 23, Loss: 4.655791282653809
Epoch 24, Loss: 4.6546125411987305
Epoch 25, Loss: 4.655964374542236
Epoch 26, Loss: 4.655085563659668
Epoch 27, Loss: 4.664669990539551
Epoch 28, Loss: 4.655973434448242
Epoch 29, Loss: 4.655789375305176
Epoch 30, Loss: 4.654461860656738
 ~ Training finished ~
 Score: V accuracy:0.5930482928329744; J accuracy: 1.0
Iteration 65 of 72
   ~ Training for parameters: Hid_layer_size: [1500, 1000, 750, 500, 200], lr: 0.0001, n_drop: 0.4, use j: True ~
Epoch 1, Loss: 5.147603988647461
Epoch 2, Loss: 5.043727874755859
Epoch 3, Loss: 5.0267815589904785
Epoch 4, Loss: 4.950517654418945
Epoch 5, Loss: 4.904641151428223
Epoch 6, Loss: 4.903581619262695
Epoch 7, Loss: 5.0271453857421875
Epoch 8, Loss: 4.9017415046691895
Epoch 9, Loss: 4.9025726318359375
Epoch 10, Loss: 4.903833866119385
Epoch 11, Loss: 4.903063774108887
Epoch 12, Loss: 4.905656814575195
Epoch 13, Loss: 4.777371883392334
Epoch 14, Loss: 4.655247211456299
Epoch 15, Loss: 4.655511379241943
Epoch 16, Loss: 4.656226634979248
Epoch 17, Loss: 4.855616569519043
Epoch 18, Loss: 4.692769527435303
Epoch 19, Loss: 4.659070014953613
Epoch 20, Loss: 4.655123233795166
Epoch 21, Loss: 4.6559529304504395
Epoch 22, Loss: 4.653646469116211
Epoch 23, Loss: 4.654422760009766
Epoch 24, Loss: 4.670274257659912
Epoch 25, Loss: 4.530029773712158
Epoch 26, Loss: 4.528589248657227
Epoch 27, Loss: 4.529725074768066
Epoch 28, Loss: 4.529051303863525
Epoch 29, Loss: 4.653934478759766
Epoch 30, Loss: 4.530950546264648
 ~ Training finished ~
 Score: V accuracy:0.5810519840049215; J accuracy: 1.0
Iteration 66 of 72
   ~ Training for parameters: Hid_layer_size: [1500, 1000, 750, 500, 200], lr: 0.0001, n_drop: 0.4, use j: False ~
Epoch 1, Loss: 4.978914260864258
Epoch 2, Loss: 4.995949745178223
Epoch 3, Loss: 4.917545795440674
Epoch 4, Loss: 4.852855682373047
Epoch 5, Loss: 4.784694671630859
Epoch 6, Loss: 4.779271125793457
Epoch 7, Loss: 4.7789387702941895
Epoch 8, Loss: 4.779384613037109
Epoch 9, Loss: 4.779189586639404
Epoch 10, Loss: 4.775720119476318
Epoch 11, Loss: 4.778566360473633
Epoch 12, Loss: 4.780355930328369
Epoch 13, Loss: 4.780213356018066
Epoch 14, Loss: 4.780243873596191
Epoch 15, Loss: 4.779563903808594
Epoch 16, Loss: 4.778982162475586
Epoch 17, Loss: 4.656808853149414
Epoch 18, Loss: 4.654909133911133
Epoch 19, Loss: 4.65550422668457
Epoch 20, Loss: 4.780850887298584
Epoch 21, Loss: 4.533114433288574
Epoch 22, Loss: 4.529833793640137
Epoch 23, Loss: 4.581338405609131
Epoch 24, Loss: 4.530972003936768
Epoch 25, Loss: 4.532853126525879
Epoch 26, Loss: 4.529494285583496
Epoch 27, Loss: 4.531681537628174
Epoch 28, Loss: 4.531298637390137
Epoch 29, Loss: 4.608000755310059
Epoch 30, Loss: 4.529432773590088
 ~ Training finished ~
 Score: V accuracy:0.597662257766841; J accuracy: 1.0
Iteration 67 of 72
   ~ Training for parameters: Hid_layer_size: [1500, 1000, 750, 500, 200], lr: 1e-05, n_drop: 0.2, use j: True ~
Epoch 1, Loss: 5.41274881362915
Epoch 2, Loss: 5.1342244148254395
Epoch 3, Loss: 5.117153644561768
Epoch 4, Loss: 5.03035306930542
Epoch 5, Loss: 4.934159755706787
Epoch 6, Loss: 4.781064510345459
Epoch 7, Loss: 4.840585708618164
Epoch 8, Loss: 4.786149501800537
Epoch 9, Loss: 4.78446102142334
Epoch 10, Loss: 4.827794075012207
Epoch 11, Loss: 4.785321235656738
Epoch 12, Loss: 4.776416301727295
Epoch 13, Loss: 4.659580707550049
Epoch 14, Loss: 4.652943134307861
Epoch 15, Loss: 4.654304504394531
Epoch 16, Loss: 4.720703125
Epoch 17, Loss: 4.652528762817383
Epoch 18, Loss: 4.6510329246521
Epoch 19, Loss: 4.657435894012451
Epoch 20, Loss: 4.654749393463135
Epoch 21, Loss: 4.652426242828369
Epoch 22, Loss: 4.658847808837891
Epoch 23, Loss: 4.66310453414917
Epoch 24, Loss: 4.656316757202148
Epoch 25, Loss: 4.650195121765137
Epoch 26, Loss: 4.6516618728637695
Epoch 27, Loss: 4.652144908905029
Epoch 28, Loss: 4.6502227783203125
Epoch 29, Loss: 4.5684895515441895
Epoch 30, Loss: 4.529402256011963
 ~ Training finished ~
 Score: V accuracy:0.5742848354352507; J accuracy: 1.0
Iteration 68 of 72
   ~ Training for parameters: Hid_layer_size: [1500, 1000, 750, 500, 200], lr: 1e-05, n_drop: 0.2, use j: False ~
Epoch 1, Loss: 5.379567623138428
Epoch 2, Loss: 5.270779609680176
Epoch 3, Loss: 5.169285297393799
Epoch 4, Loss: 5.151800155639648
Epoch 5, Loss: 5.148929595947266
Epoch 6, Loss: 5.150796890258789
Epoch 7, Loss: 5.203929901123047
Epoch 8, Loss: 5.151333808898926
Epoch 9, Loss: 5.154950141906738
Epoch 10, Loss: 5.150394439697266
Epoch 11, Loss: 5.150866508483887
Epoch 12, Loss: 5.0427117347717285
Epoch 13, Loss: 5.024853706359863
Epoch 14, Loss: 5.0321879386901855
Epoch 15, Loss: 5.0418548583984375
Epoch 16, Loss: 5.026434421539307
Epoch 17, Loss: 5.027642250061035
Epoch 18, Loss: 4.907533645629883
Epoch 19, Loss: 4.902400970458984
Epoch 20, Loss: 4.919870376586914
Epoch 21, Loss: 4.904764175415039
Epoch 22, Loss: 4.936982154846191
Epoch 23, Loss: 4.904294967651367
Epoch 24, Loss: 4.901991367340088
Epoch 25, Loss: 4.904036045074463
Epoch 26, Loss: 4.90197229385376
Epoch 27, Loss: 4.901665687561035
Epoch 28, Loss: 4.932987689971924
Epoch 29, Loss: 4.899979591369629
Epoch 30, Loss: 4.903040885925293
 ~ Training finished ~
 Score: V accuracy:0.40018455859735463; J accuracy: 1.0
Iteration 69 of 72
   ~ Training for parameters: Hid_layer_size: [1500, 1000, 750, 500, 200], lr: 1e-05, n_drop: 0.3, use j: True ~
Epoch 1, Loss: 5.399753570556641
Epoch 2, Loss: 5.177248477935791
Epoch 3, Loss: 5.057589054107666
Epoch 4, Loss: 5.119903087615967
Epoch 5, Loss: 5.037630081176758
Epoch 6, Loss: 5.044103145599365
Epoch 7, Loss: 4.952574729919434
Epoch 8, Loss: 5.0263352394104
Epoch 9, Loss: 5.105852127075195
Epoch 10, Loss: 5.019631385803223
Epoch 11, Loss: 4.940982341766357
Epoch 12, Loss: 4.90128231048584
Epoch 13, Loss: 4.899044990539551
Epoch 14, Loss: 4.903602600097656
Epoch 15, Loss: 4.932345867156982
Epoch 16, Loss: 4.8974289894104
Epoch 17, Loss: 4.927196025848389
Epoch 18, Loss: 4.897245407104492
Epoch 19, Loss: 4.899134635925293
Epoch 20, Loss: 4.837114334106445
Epoch 21, Loss: 4.8635454177856445
Epoch 22, Loss: 4.79098653793335
Epoch 23, Loss: 4.866467475891113
Epoch 24, Loss: 4.885995864868164
Epoch 25, Loss: 4.804758071899414
Epoch 26, Loss: 4.8851094245910645
Epoch 27, Loss: 4.780091285705566
Epoch 28, Loss: 4.775622367858887
Epoch 29, Loss: 4.806243896484375
Epoch 30, Loss: 4.803134441375732
 ~ Training finished ~
 Score: V accuracy:0.5078437403875731; J accuracy: 1.0
Iteration 70 of 72
   ~ Training for parameters: Hid_layer_size: [1500, 1000, 750, 500, 200], lr: 1e-05, n_drop: 0.3, use j: False ~
Epoch 1, Loss: 5.415911674499512
Epoch 2, Loss: 5.270654678344727
Epoch 3, Loss: 5.154304027557373
Epoch 4, Loss: 5.157902240753174
Epoch 5, Loss: 5.21727991104126
Epoch 6, Loss: 5.146501541137695
Epoch 7, Loss: 5.165075302124023
Epoch 8, Loss: 5.153431415557861
Epoch 9, Loss: 5.147976875305176
Epoch 10, Loss: 5.067227363586426
Epoch 11, Loss: 5.034913539886475
Epoch 12, Loss: 5.042971134185791
Epoch 13, Loss: 5.026731491088867
Epoch 14, Loss: 5.026803970336914
Epoch 15, Loss: 5.02396297454834
Epoch 16, Loss: 4.950514316558838
Epoch 17, Loss: 4.805189609527588
Epoch 18, Loss: 4.876453399658203
Epoch 19, Loss: 4.794853210449219
Epoch 20, Loss: 4.8541669845581055
Epoch 21, Loss: 4.7785539627075195
Epoch 22, Loss: 4.775393009185791
Epoch 23, Loss: 4.65757942199707
Epoch 24, Loss: 4.680577278137207
Epoch 25, Loss: 4.65731954574585
Epoch 26, Loss: 4.6574859619140625
Epoch 27, Loss: 4.653175354003906
Epoch 28, Loss: 4.6565656661987305
Epoch 29, Loss: 4.650039196014404
Epoch 30, Loss: 4.652555465698242
 ~ Training finished ~
 Score: V accuracy:0.531528760381421; J accuracy: 1.0
Iteration 71 of 72
   ~ Training for parameters: Hid_layer_size: [1500, 1000, 750, 500, 200], lr: 1e-05, n_drop: 0.4, use j: True ~
Epoch 1, Loss: 5.421469211578369
Epoch 2, Loss: 5.315175533294678
Epoch 3, Loss: 5.152570724487305
Epoch 4, Loss: 5.081756114959717
Epoch 5, Loss: 5.031597137451172
Epoch 6, Loss: 5.027257919311523
Epoch 7, Loss: 5.011215686798096
Epoch 8, Loss: 5.136490821838379
Epoch 9, Loss: 5.044384002685547
Epoch 10, Loss: 5.010525226593018
Epoch 11, Loss: 5.022024154663086
Epoch 12, Loss: 4.8617658615112305
Epoch 13, Loss: 4.894633769989014
Epoch 14, Loss: 4.824434280395508
Epoch 15, Loss: 4.885781764984131
Epoch 16, Loss: 4.81251335144043
Epoch 17, Loss: 4.787652015686035
Epoch 18, Loss: 4.866303443908691
Epoch 19, Loss: 4.81381893157959
Epoch 20, Loss: 4.7826032638549805
Epoch 21, Loss: 4.806210517883301
Epoch 22, Loss: 4.794682502746582
Epoch 23, Loss: 4.782534122467041
Epoch 24, Loss: 4.844498157501221
Epoch 25, Loss: 4.779026508331299
Epoch 26, Loss: 4.7844743728637695
Epoch 27, Loss: 4.775084972381592
Epoch 28, Loss: 4.776593208312988
Epoch 29, Loss: 4.7771220207214355
Epoch 30, Loss: 4.811256408691406
 ~ Training finished ~
 Score: V accuracy:0.47923715779760073; J accuracy: 0.9646262688403568
Iteration 72 of 72
   ~ Training for parameters: Hid_layer_size: [1500, 1000, 750, 500, 200], lr: 1e-05, n_drop: 0.4, use j: False ~
Epoch 1, Loss: 5.544333457946777
Epoch 2, Loss: 5.353860855102539
Epoch 3, Loss: 5.26516580581665
Epoch 4, Loss: 5.159674167633057
Epoch 5, Loss: 5.146101951599121
Epoch 6, Loss: 5.152731895446777
Epoch 7, Loss: 5.2041168212890625
Epoch 8, Loss: 5.056732177734375
Epoch 9, Loss: 5.0427961349487305
Epoch 10, Loss: 5.037478446960449
Epoch 11, Loss: 5.029435157775879
Epoch 12, Loss: 5.024622917175293
Epoch 13, Loss: 5.024637222290039
Epoch 14, Loss: 5.020271301269531
Epoch 15, Loss: 5.028088092803955
Epoch 16, Loss: 5.031872749328613
Epoch 17, Loss: 5.024595260620117
Epoch 18, Loss: 5.02362060546875
Epoch 19, Loss: 5.024787425994873
Epoch 20, Loss: 5.028961181640625
Epoch 21, Loss: 5.021055698394775
Epoch 22, Loss: 4.905801296234131
Epoch 23, Loss: 4.974159240722656
Epoch 24, Loss: 4.903521537780762
Epoch 25, Loss: 4.880001068115234
Epoch 26, Loss: 4.668149948120117
Epoch 27, Loss: 4.7332353591918945
Epoch 28, Loss: 4.706857681274414
Epoch 29, Loss: 4.663914203643799
Epoch 30, Loss: 4.7136688232421875
 ~ Training finished ~
 Score: V accuracy:0.4715472162411566; J accuracy: 1.0
